from __future__ import annotations

import ast
import base64
from collections import deque
from contextlib import contextmanager
import hashlib
import json
import math
import os
import pickle
import queue
import re
import time
import logging
import multiprocessing as mp
import random
from dataclasses import asdict
from typing import Any, Dict, Iterator, List, Sequence, Tuple

import torch
import torch.nn.functional as F
import yaml

from fitness.free_loss_fidelity import (
    FreeLossFidelityConfig,
    evaluate_free_loss_candidate,
    evaluate_po_baseline_rl4co,
)
from fitness.ptp_high_fidelity import (
    HighFidelityConfig,
    _set_seed,
    resolve_pomo_size,
    get_hf_epoch_plan,
    get_total_hf_train_steps,
)
from ptp_discovery.free_loss_compiler import CompileError
from ptp_discovery.free_loss_gates import (
    DynamicGateResult,
    AffineInvarianceGateResult,
    ObjectiveSensitivityGateResult,
    PreferenceSemanticGateResult,
    StaticGateResult,
    run_affine_invariance_gate,
    run_dynamic_gates,
    run_objective_sensitivity_gate,
    run_preference_semantic_gates,
    run_static_gates,
    supported_keys_for_mode,
)
from ptp_discovery.free_loss_ir import FreeLossIR, ir_from_json
from ptp_discovery.free_loss_llm_ops import (
    compile_free_loss_candidate,
    crossover_free_loss,
    e2_free_loss,
    generate_free_loss_candidate,
    m2_tune_hparams,
    m3_simplify_loss,
    mutate_free_loss,
    repair_free_loss,
    repair_from_gate_failure,
    repair_expects_with_prompt,
)

from torch.optim import Adam


LOGGER = logging.getLogger("ptp_discovery.free_loss_eoh")


def _classify_failure(stage: str, reason: str) -> str:
    """Map free-loss gate failures to coarse error codes.

    These codes are fed into LLM repair / mutation prompts so that the
    model can learn which failure modes to avoid.
    """

    msg = (reason or "").lower()
    stage = stage.lower()

    if stage == "static":
        if "missing name" in msg:
            return "E_STATIC_MISSING_NAME"
        if "missing pseudocode" in msg:
            return "E_STATIC_MISSING_PSEUDOCODE"
        if "duplicate_candidate" in msg:
            return "E_DUPLICATE"
        if "operators_used must be non-empty" in msg:
            return "E_STATIC_EMPTY_OPERATORS"
        if "non-whitelisted operators" in msg:
            return "E_OPERATOR_VIOLATION"
        if "returns must describe a scalar" in msg:
            return "E_EXPECTS_RETURNS_MISMATCH"
        if "hyperparameter" in msg and "non-finite" in msg:
            return "E_STATIC_NON_FINITE_HYPERPARAM"
        return "E_STATIC_OTHER"

    if stage == "compile":
        if "failed to parse json" in msg or "no json object found" in msg:
            return "E_JSON_PARSE"
        return "E_COMPILE_ERROR"

    if stage == "dynamic":
        if "missing_dependency" in msg:
            return "E_MISSING_DEPENDENCY"
        if (
            "missing_batch_key" in msg
            or "extra_batch_key" in msg
            or "invalid_expects" in msg
            or "missing_expects" in msg
            or "unsupported_expects" in msg
        ):
            return "E_INPUT_MISMATCH"
        if "pref_semantic_violation" in msg:
            return "E_PREF_SEMANTIC"
        if "pref_" in msg:
            return "E_PREF_SEMANTIC"
        if "insensitive_to_objective" in msg:
            return "E_CO_SENSITIVITY"
        if "affine_invariance_violation" in msg:
            return "E_CO_INVARIANCE"
        if "loss is not finite" in msg:
            return "E_RUNTIME_NAN_LOSS"
        if "nan/inf in gradients" in msg:
            return "E_RUNTIME_NAN_GRAD"
        if "backward_error" in msg:
            return "E_BACKWARD_ERROR"
        if "forward_error" in msg:
            return "E_FORWARD_ERROR"
        if "grad_norm" in msg and "exceeds max" in msg:
            return "E_GRAD_EXPLODE"
        if "outside soft range" in msg or "soft range" in msg:
            return "E_LOSS_OUT_OF_RANGE"
        return "E_DYNAMIC_OTHER"

    return "E_UNKNOWN"


class _SignatureNormalizer(ast.NodeTransformer):
    def visit_Constant(self, node: ast.Constant) -> ast.AST:  # type: ignore[override]
        if isinstance(node.value, (int, float)):
            return ast.copy_location(ast.Constant(value=0), node)
        if isinstance(node.value, str):
            return ast.copy_location(ast.Constant(value=""), node)
        return node

    def visit_Name(self, node: ast.Name) -> ast.AST:  # type: ignore[override]
        return ast.copy_location(ast.Name(id="v", ctx=node.ctx), node)

    def visit_arg(self, node: ast.arg) -> ast.AST:  # type: ignore[override]
        return ast.copy_location(ast.arg(arg="v", annotation=None), node)


def _candidate_signature(ir: FreeLossIR) -> str:
    code_str = (ir.code or "").strip()
    if code_str:
        try:
            tree = ast.parse(code_str, mode="exec")
            tree = _SignatureNormalizer().visit(tree)
            ast.fix_missing_locations(tree)
            dump = ast.dump(tree, include_attributes=False)
        except Exception:
            dump = code_str
        digest = hashlib.sha1(dump.encode("utf-8")).hexdigest()
        return f"code:{digest}"

    ops = ",".join(sorted(ir.operators_used or []))
    hp_keys = ",".join(sorted((ir.hyperparams or {}).keys()))
    return f"template:{ops}|{hp_keys}"


def _behavior_descriptor(
    compiled: Any,
    *,
    deltas: Sequence[float],
    batch_size: int,
) -> List[float] | None:
    if not deltas:
        return []

    vec: List[float] = []
    for delta in deltas:
        cost_a = torch.rand(batch_size)
        gap = torch.rand(batch_size)
        cost_b = cost_a + gap

        log_prob_l = torch.empty(batch_size).uniform_(-20.0, 0.0)
        log_prob_w = log_prob_l + float(delta)
        log_prob_l = log_prob_l.clone().detach().requires_grad_(True)
        log_prob_w = log_prob_w.clone().detach().requires_grad_(True)

        batch = {
            "cost_a": cost_a,
            "cost_b": cost_b,
            "log_prob_w": log_prob_w,
            "log_prob_l": log_prob_l,
        }
        try:
            loss = compiled.loss_fn(batch=batch, model_output={}, extra={})
        except Exception:
            return None
        if not isinstance(loss, torch.Tensor):
            return None
        if loss.numel() != 1:
            return None
        if not torch.isfinite(loss).all().item():
            return None

        grad_w, grad_l = torch.autograd.grad(
            loss,
            [log_prob_w, log_prob_l],
            allow_unused=True,
        )
        if grad_w is None or grad_l is None:
            return None

        vec.append(float(loss.item()))
        grad_delta = (grad_w - grad_l).mean().item()
        vec.append(float(grad_delta))

    return vec


_THOUGHT_STOPWORDS = {
    "a",
    "an",
    "and",
    "are",
    "as",
    "at",
    "be",
    "by",
    "for",
    "from",
    "in",
    "is",
    "it",
    "its",
    "of",
    "on",
    "or",
    "that",
    "the",
    "this",
    "to",
    "with",
    "we",
    "you",
    "your",
    "our",
    "their",
    "not",
    "only",
    "must",
    "should",
    "can",
    "may",
    "use",
    "using",
    "used",
    "loss",
    "preference",
    "preferences",
    "logp",
    "logprob",
    "prob",
    "probability",
    "cost",
    "gap",
    "delta",
}


def _thought_tokens(ir: FreeLossIR, *, max_tokens: int = 32) -> List[str]:
    text = " ".join(
        [
            str(ir.intuition or ""),
            str(ir.pseudocode or ""),
            str(getattr(ir, "theoretical_basis", "") or ""),
        ]
    ).lower()
    raw = re.findall(r"[a-zA-Z][a-zA-Z0-9_+-]{1,}", text)
    counts: Dict[str, int] = {}
    for tok in raw:
        if tok in _THOUGHT_STOPWORDS:
            continue
        if len(tok) < 3:
            continue
        counts[tok] = counts.get(tok, 0) + 1
    ranked = sorted(counts.items(), key=lambda kv: (-kv[1], kv[0]))
    return [t for t, _ in ranked[:max_tokens]]


def _jaccard_distance(a: Sequence[str], b: Sequence[str]) -> float:
    set_a = set(a)
    set_b = set(b)
    if not set_a and not set_b:
        return 0.0
    union = set_a | set_b
    inter = set_a & set_b
    return 1.0 - (len(inter) / len(union))


def _descriptor_distance(
    a: Dict[str, Any],
    b: Dict[str, Any],
    *,
    ops_weight: float,
    hparam_weight: float,
    behavior_weight: float,
    thought_weight: float,
) -> float:
    beh_a = a.get("behavior") or []
    beh_b = b.get("behavior") or []
    beh_dist = 0.0
    if beh_a and beh_b and len(beh_a) == len(beh_b):
        beh_dist = sum((x - y) ** 2 for x, y in zip(beh_a, beh_b)) ** 0.5

    ops_dist = _jaccard_distance(a.get("ops", []), b.get("ops", []))
    hp_dist = _jaccard_distance(a.get("hyperparams", []), b.get("hyperparams", []))
    thought_dist = _jaccard_distance(a.get("thought", []), b.get("thought", []))

    return (
        behavior_weight * beh_dist
        + ops_weight * ops_dist
        + hparam_weight * hp_dist
        + thought_weight * thought_dist
    )


def _novelty_score(
    desc: Dict[str, Any] | None,
    archive: List[Dict[str, Any]],
    *,
    k: int,
    ops_weight: float,
    hparam_weight: float,
    behavior_weight: float,
    thought_weight: float,
) -> float:
    if desc is None:
        return 0.0
    if not archive:
        return 0.0
    distances = [
        _descriptor_distance(
            desc,
            other,
            ops_weight=ops_weight,
            hparam_weight=hparam_weight,
            behavior_weight=behavior_weight,
            thought_weight=thought_weight,
        )
        for other in archive
    ]
    distances.sort()
    top_k = distances[: max(1, min(k, len(distances)))]
    return float(sum(top_k) / len(top_k))


def _pareto_ranks(entries: List[Dict[str, Any]]) -> List[int]:
    n = len(entries)
    ranks = [0] * n
    dominated_by = [0] * n
    dominates: List[List[int]] = [[] for _ in range(n)]
    fronts: List[List[int]] = [[]]

    def _dominates(a: Dict[str, Any], b: Dict[str, Any]) -> bool:
        a_fit = float(a["fitness"]["hf_like_score"])
        b_fit = float(b["fitness"]["hf_like_score"])
        a_nov = float(a.get("novelty", 0.0))
        b_nov = float(b.get("novelty", 0.0))
        return (a_fit <= b_fit and a_nov >= b_nov) and (a_fit < b_fit or a_nov > b_nov)

    for i in range(n):
        for j in range(n):
            if i == j:
                continue
            if _dominates(entries[i], entries[j]):
                dominates[i].append(j)
            elif _dominates(entries[j], entries[i]):
                dominated_by[i] += 1
        if dominated_by[i] == 0:
            ranks[i] = 0
            fronts[0].append(i)

    current = 0
    while fronts[current]:
        next_front: List[int] = []
        for i in fronts[current]:
            for j in dominates[i]:
                dominated_by[j] -= 1
                if dominated_by[j] == 0:
                    ranks[j] = current + 1
                    next_front.append(j)
        current += 1
        fronts.append(next_front)

    return ranks


def _select_parents(entries: List[Dict[str, Any]], k: int) -> List[Dict[str, Any]]:
    if not entries:
        return []
    ranks = _pareto_ranks(entries)
    ranked = sorted(
        zip(entries, ranks),
        key=lambda x: (x[1], -float(x[0].get("novelty", 0.0)), float(x[0]["fitness"]["hf_like_score"])),
    )
    return [entry for entry, _ in ranked[:k]]


def _summarize_diversity(archive: List[Dict[str, Any]], top_k: int = 5) -> Dict[str, Any]:
    op_counts: Dict[str, int] = {}
    hp_counts: Dict[str, int] = {}
    for entry in archive:
        ops = tuple(sorted(entry.get("ops", [])))
        op_counts[str(ops)] = op_counts.get(str(ops), 0) + 1
        hps = tuple(sorted(entry.get("hyperparams", [])))
        hp_counts[str(hps)] = hp_counts.get(str(hps), 0) + 1

    op_common = sorted(op_counts.items(), key=lambda kv: kv[1], reverse=True)[:top_k]
    hp_common = sorted(hp_counts.items(), key=lambda kv: kv[1], reverse=True)[:top_k]

    return {
        "common_operator_sets": [{"operators_used": k, "count": v} for k, v in op_common],
        "common_hparam_keys": [{"hyperparams": k, "count": v} for k, v in hp_common],
    }


def _build_auto_seed_objectives() -> List[Dict[str, Any]]:
    return [
        {
            "name": "seed_logsigmoid",
            "type": "auto_seed",
            "description": "Base Bradley-Terry style loss: -logsigmoid(alpha * (logp_w - logp_l)).",
            "operators_used": ["logsigmoid"],
            "hyperparams": {"alpha": 1.0},
        },
        {
            "name": "seed_softplus_margin",
            "type": "auto_seed",
            "description": "Softplus hinge: softplus(margin - (logp_w - logp_l)).",
            "operators_used": ["softplus"],
            "hyperparams": {"margin": 0.5},
        },
        {
            "name": "seed_focal_logsigmoid",
            "type": "auto_seed",
            "description": "Focal modulated: exp(gamma * log(1 - sigmoid(delta))) * -logsigmoid(delta).",
            "operators_used": ["sigmoid", "logsigmoid", "exp", "log"],
            "hyperparams": {"gamma": 2.0},
        },
        {
            "name": "seed_cost_gap_margin",
            "type": "auto_seed",
            "description": "Margin grows with cost gap: margin = beta * (cost_b - cost_a).",
            "operators_used": ["logsigmoid"],
            "hyperparams": {"beta": 1.0},
        },
        {
            "name": "seed_softplus_cost_scale",
            "type": "auto_seed",
            "description": "Scale by softplus(cost_gap): softplus(cost_gap) * -logsigmoid(delta).",
            "operators_used": ["softplus", "logsigmoid"],
            "hyperparams": {},
        },
        {
            "name": "seed_tanh_margin",
            "type": "auto_seed",
            "description": "Tanh margin: margin = tanh(scale * cost_gap).",
            "operators_used": ["tanh", "logsigmoid"],
            "hyperparams": {"scale": 1.0},
        },
        {
            "name": "seed_exp_penalty",
            "type": "auto_seed",
            "description": "Exponential penalty on negative delta: exp(-delta).",
            "operators_used": ["exp"],
            "hyperparams": {},
        },
        {
            "name": "seed_sigmoid_margin",
            "type": "auto_seed",
            "description": "Sigmoid margin: margin = sigmoid(beta * cost_gap).",
            "operators_used": ["sigmoid", "logsigmoid"],
            "hyperparams": {"beta": 1.0},
        },
        {
            "name": "seed_mix_logsigmoid_softplus",
            "type": "auto_seed",
            "description": "Mixture: alpha * logsigmoid + (1-alpha) * softplus hinge.",
            "operators_used": ["logsigmoid", "softplus", "sigmoid"],
            "hyperparams": {"alpha": 0.5},
        },
        {
            "name": "seed_zscore_margin",
            "type": "auto_seed",
            "description": "Z-score cost gap to set margin scale.",
            "operators_used": ["zscore", "logsigmoid"],
            "hyperparams": {"scale": 1.0},
        },
    ]

def _build_failure_payload(
    *,
    generation: int,
    index: int,
    attempt: int,
    stage: str,
    code: str,
    message: str,
    extra: Dict[str, Any] | None = None,
) -> Dict[str, Any]:
    payload: Dict[str, Any] = {
        "generation": int(generation),
        "index": int(index),
        "attempt": int(attempt),
        "stage": stage,
        "code": code,
        "message": message,
    }
    if extra:
        payload["extra"] = dict(extra)
    return payload


def _build_global_feedback(
    *,
    elites: List[Dict[str, Any]],
    gates_log: List[Dict[str, Any]],
    burn_in_objectives: List[Dict[str, Any]],
    baseline_hf_score: float | None,
    diversity_archive: List[Dict[str, Any]] | None = None,
    max_elites: int = 8,
    max_failures: int = 64,
) -> Dict[str, Any]:
    """Summarize recent search history for LLM prompts.

    Includes:
    - burn-in objectives (e.g., baseline po_loss)
    - a small set of best elites with metrics and IR hints
    - a histogram of recent gate failures by error code
    """

    # Summarize elites (best-performing candidates across generations).
    sorted_elites = sorted(
        elites,
        key=lambda e: float(e["fitness"]["hf_like_score"]),
    )
    elite_summaries: List[Dict[str, Any]] = []
    for entry in sorted_elites[:max_elites]:
        ir: FreeLossIR = entry["ir"]
        fitness = entry["fitness"]
        elite_summaries.append(
            {
                "generation": int(entry.get("generation", -1)),
                "index": int(entry.get("index", -1)),
                "name": ir.name,
                "theoretical_basis": getattr(ir, "theoretical_basis", ""),
                "operators_used": list(ir.operators_used),
                "hyperparams": dict(ir.hyperparams),
                "hf_like_score": float(fitness.get("hf_like_score", float("inf"))),
                "validation_objective": float(fitness.get("validation_objective", float("inf"))),
                "generalization_penalty": float(fitness.get("generalization_penalty", 0.0)),
                "epoch_objective_mean": float(fitness.get("epoch_objective_mean", float("inf")))
                if fitness.get("epoch_objective_mean") is not None
                else None,
                "epoch_baseline_violations": fitness.get("epoch_baseline_violations"),
                "pair_count": int(fitness.get("pair_count", 0) or 0),
            }
        )

    # Summarize recent failures.
    recent_fail_entries = [
        e
        for e in gates_log
        if (not e.get("static_ok", True)) or (e.get("dynamic_ok") is False)
    ][-max_failures:]

    error_stats: Dict[str, int] = {}
    for e in recent_fail_entries:
        for key in ("static_error_code", "dynamic_error_code"):
            code = e.get(key)
            if not code:
                continue
            error_stats[code] = error_stats.get(code, 0) + 1

    failures_by_code = [
        {"code": code, "count": count}
        for code, count in sorted(error_stats.items(), key=lambda kv: kv[1], reverse=True)
    ]

    failure_examples: List[Dict[str, Any]] = []
    for e in recent_fail_entries:
        failure_examples.append(
            {
                "generation": int(e.get("generation", -1)),
                "index": int(e.get("index", -1)),
                "attempt": int(e.get("attempt", 0)),
                "static_ok": bool(e.get("static_ok", True)),
                "dynamic_ok": e.get("dynamic_ok"),
                "static_error_code": e.get("static_error_code"),
                "dynamic_error_code": e.get("dynamic_error_code"),
                "static_reason": e.get("static_reason"),
                "dynamic_reason": e.get("dynamic_reason"),
            }
        )

    # Suggest a coarse search mode for the LLM.
    suggested_mode = "explore"
    if elite_summaries and baseline_hf_score is not None:
        best_score = elite_summaries[0]["hf_like_score"]
        improvement = float(baseline_hf_score) - float(best_score)
        if improvement <= 0.0:
            suggested_mode = "explore"
        elif improvement < 0.1:
            suggested_mode = "combine"
        else:
            suggested_mode = "refine"

    diversity_summary = _summarize_diversity(diversity_archive or [])

    return {
        "burn_in_objectives": burn_in_objectives,
        "recent_elites": elite_summaries,
        "recent_failures": {
            "by_code": failures_by_code,
            "examples": failure_examples,
        },
        "diversity_summary": diversity_summary,
        "suggested_mode": suggested_mode,
    }


def _write_run_analysis(
    run_dir: str,
    *,
    baseline_hf_score: float | None,
    generations: int,
    population_size: int,
    gates_log: List[Dict[str, Any]] | None = None,
    gate_failure_stats: Dict[str, int] | None = None,
    elites: List[Dict[str, Any]],
) -> None:
    """Emit a lightweight JSON summary for downstream analysis.

    This aggregates gate failure statistics and highlights the best
    discovered loss, so that external tools (or LLMs) can inspect
    the run without re-parsing all logs.
    """

    error_stats: Dict[str, int] = {}
    if gate_failure_stats is not None:
        error_stats = {str(k): int(v) for k, v in gate_failure_stats.items()}
    elif gates_log is not None:
        for entry in gates_log:
            for key in ("static_error_code", "dynamic_error_code"):
                code = entry.get(key)
                if not code:
                    continue
                error_stats[code] = error_stats.get(code, 0) + 1

    failures_by_code = [
        {"code": code, "count": count}
        for code, count in sorted(error_stats.items(), key=lambda kv: kv[1], reverse=True)
    ]

    best_summary: Dict[str, Any] | None = None
    if elites:
        best = sorted(elites, key=lambda e: float(e["fitness"]["hf_like_score"]))[0]
        ir: FreeLossIR = best["ir"]
        fitness = best["fitness"]
        best_summary = {
            "generation": int(best.get("generation", -1)),
            "index": int(best.get("index", -1)),
            "name": ir.name,
            "theoretical_basis": getattr(ir, "theoretical_basis", ""),
            "operators_used": list(ir.operators_used),
            "hyperparams": dict(ir.hyperparams),
            "hf_like_score": float(fitness.get("hf_like_score", float("inf"))),
            "validation_objective": float(fitness.get("validation_objective", float("inf"))),
            "generalization_penalty": float(fitness.get("generalization_penalty", 0.0)),
            "epoch_objective_mean": float(fitness.get("epoch_objective_mean", float("inf")))
            if fitness.get("epoch_objective_mean") is not None
            else None,
            "epoch_baseline_violations": fitness.get("epoch_baseline_violations"),
            "pair_count": int(fitness.get("pair_count", 0) or 0),
        }

    summary = {
        "generations": int(generations),
        "population_size": int(population_size),
        "baseline_hf_score": float(baseline_hf_score) if baseline_hf_score is not None else None,
        "gate_failure_stats": {
            "by_code": failures_by_code,
        },
        "best_candidate": best_summary,
    }

    path = os.path.join(run_dir, "analysis_summary.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)


def _get_available_devices(base_device: str) -> List[str]:
    """Return a list of logical device strings for parallel evaluation.

    - If base_device is 'cuda', expose all visible CUDA devices as
      ['cuda:0', 'cuda:1', ...].
    - If base_device has an explicit index (e.g., 'cuda:3'), keep it as a
      single-device list.
    - For CPU or unknown strings, fall back to [base_device].
    """

    base_device = str(base_device)
    if base_device.startswith("cuda:"):
        return [base_device]
    if base_device == "cuda" and torch.cuda.is_available():
        count = torch.cuda.device_count()
        if count <= 0:
            return [base_device]
        return [f"cuda:{i}" for i in range(count)]
    return [base_device]


def _compute_early_eval_steps(cfg_yaml: Dict[str, Any], hf_cfg: HighFidelityConfig) -> int:
    total_steps = get_total_hf_train_steps(hf_cfg)
    early_eval_epochs = int(cfg_yaml.get("early_eval_epochs", 0) or 0)
    early_eval_instances_per_epoch = int(
        cfg_yaml.get("early_eval_instances_per_epoch", 0) or 0
    )
    early_eval_steps_cfg = cfg_yaml.get("early_eval_steps")

    if early_eval_epochs > 0:
        instances_per_epoch = early_eval_instances_per_epoch
        if instances_per_epoch <= 0:
            instances_per_epoch = int(hf_cfg.hf_instances_per_epoch or 0)
        if instances_per_epoch > 0:
            batch_size = max(int(hf_cfg.train_batch_size), 1)
            steps_per_epoch = math.ceil(instances_per_epoch / batch_size)
            steps = early_eval_epochs * steps_per_epoch
        else:
            steps = 0
    elif early_eval_steps_cfg is not None:
        steps = int(early_eval_steps_cfg or 0)
    else:
        steps = min(100, total_steps)

    if steps <= 0:
        return 0
    return min(int(steps), int(total_steps))


def _worker_evaluate_candidate(args: Tuple[
    Dict[str, Any],
    Dict[str, Any],
    Dict[str, Any],
    str,
    List[str],
    str,
    int,
    int,
    float | None,
    List[float] | None,
    int,
]) -> Tuple[int, Dict[str, Any]]:
    """Worker process: compile and evaluate a single candidate loss.

    To keep the top-level discovery log readable, this worker redirects
    training logs for each candidate into a dedicated file under the run
    directory instead of emitting them to stdout/stderr.
    """

    (
        ir_payload,
        hf_cfg_dict,
        free_cfg_dict,
        device_str,
        operator_whitelist,
        run_dir,
        gen,
        idx,
        baseline_early_valid,
        baseline_epoch_objectives,
        early_eval_steps,
    ) = args

    # Reduce noise on stdout/stderr from worker processes.
    root_logger = logging.getLogger()
    for handler in list(root_logger.handlers):
        root_logger.removeHandler(handler)
    # Keep root logs at INFO so that evaluation utilities (e.g.,
    # `fitness.ptp_high_fidelity`) can emit progress into the per-candidate log.
    # This avoids the appearance of a "silent" hang during long evaluations.
    root_logger.setLevel(logging.INFO)

    # Route free-loss training logs to a per-candidate file.
    log_path = os.path.join(run_dir, f"gen{gen:03d}_cand{idx:03d}.log")
    fmt = logging.Formatter("[%(asctime)s] %(levelname)s:%(name)s: %(message)s")

    fl_logger = logging.getLogger("fitness.free_loss_fidelity")
    # Replace any existing handlers and proactively close them to avoid leaking
    # file descriptors when the worker evaluates multiple candidates.
    for handler in list(fl_logger.handlers):
        try:
            fl_logger.removeHandler(handler)
        finally:
            try:
                handler.close()
            except Exception:  # noqa: BLE001
                pass
    fl_logger.setLevel(logging.INFO)
    file_handler: logging.Handler
    try:
        file_handler = logging.FileHandler(log_path, mode="w", encoding="utf-8")
    except Exception as exc:  # noqa: BLE001
        # Fall back to stderr so that failures to create per-candidate logs don't
        # make the worker appear to "silently" die.
        print(
            f"[free_loss_eoh][worker] failed to open candidate log file: {log_path}: {exc}",
            flush=True,
        )
        file_handler = logging.StreamHandler()
    file_handler.setFormatter(fmt)
    fl_logger.addHandler(file_handler)
    try:
        # Also attach the per-candidate handler to the root logger so logs from
        # other modules propagate into the same file.
        root_logger.addHandler(file_handler)
    except Exception:  # noqa: BLE001
        pass

    # Reconstruct configs for this worker and override device.
    hf_cfg = HighFidelityConfig(**hf_cfg_dict)
    hf_cfg.device = device_str
    free_cfg = FreeLossFidelityConfig(
        hf=hf_cfg,
        f1_steps=int(free_cfg_dict.get("f1_steps", 32)),
        f2_steps=int(free_cfg_dict.get("f2_steps", 0)),
        f3_enabled=bool(free_cfg_dict.get("f3_enabled", False)),
        baseline_epoch_violation_weight=float(
            free_cfg_dict.get("baseline_epoch_violation_weight", 1.0)
        ),
    )

    # Reconstruct IR and compiled loss in the worker.
    ir = ir_from_json(ir_payload)
    fitness: Dict[str, Any]
    worst_score = float(1e9)

    try:
        compiled = compile_free_loss_candidate(ir, operator_whitelist=operator_whitelist)
        fitness = evaluate_free_loss_candidate(
            compiled,
            free_cfg,
            baseline_early_valid=baseline_early_valid,
            baseline_epoch_objectives=baseline_epoch_objectives,
            early_eval_steps=early_eval_steps,
        )
    except KeyboardInterrupt:
        raise
    except BaseException as exc:  # noqa: BLE001
        # If candidate evaluation fails (e.g., NaNs in probabilities or loss),
        # treat this candidate as having the worst possible fitness instead of
        # crashing the worker process.
        try:
            fl_logger = logging.getLogger("fitness.free_loss_fidelity")
            fl_logger.exception(
                "Candidate evaluation failed for gen=%d, idx=%d; assigning worst fitness.",
                gen,
                idx,
            )
        except Exception:  # noqa: BLE001
            pass

        fitness = {
            "hf_like_score": worst_score,
            "validation_objective": worst_score,
            "generalization_penalty": 0.0,
            "generalization_objectives": {},
            "epoch_objective_mean": None,
            "epoch_baseline_violations": None,
            "epoch_better_than_baseline": None,
            "train_score_mean": float("nan"),
            "train_loss_mean": float("nan"),
            "pair_count": 0,
            "early_eval": {
                "enabled": False,
                "steps": int(early_eval_steps or 0),
                "baseline_validation_objective": baseline_early_valid,
                "candidate_validation_objective": None,
                "early_stopped": False,
            },
            "epoch_eval": {
                "enabled": False,
                "steps_per_epoch": None,
                "epochs_total": 0,
                "objectives": [],
                "objective_mean": None,
                "baseline_margins": None,
                "baseline_violations": None,
                "better_than_baseline": None,
            },
        }
        fitness["eval_error"] = str(exc)
    finally:
        try:
            fl_logger = logging.getLogger("fitness.free_loss_fidelity")
            fl_logger.removeHandler(file_handler)
        except Exception:  # noqa: BLE001
            pass
        try:
            root_logger = logging.getLogger()
            root_logger.removeHandler(file_handler)
        except Exception:  # noqa: BLE001
            pass
        try:
            file_handler.close()
        except Exception:  # noqa: BLE001
            pass

        # Proactively release unused CUDA cache in this worker process to
        # reduce fragmentation and long-lived reservations across jobs.
        if torch.cuda.is_available():
            try:
                device_str = str(hf_cfg.device)
                if device_str.startswith("cuda"):
                    torch.cuda.set_device(torch.device(device_str))
                torch.cuda.empty_cache()
            except Exception:  # noqa: BLE001
                # Cache cleanup is best-effort; ignore failures to avoid masking
                # the actual training result.
                pass

    return idx, fitness


def _device_worker(
    jobs: List[Tuple[
        Dict[str, Any],
        Dict[str, Any],
        Dict[str, Any],
        str,
        List[str],
        str,
        int,
        int,
        float | None,
        List[float] | None,
        int,
    ]],
    result_queue: "mp.Queue[Tuple[int, Dict[str, Any]]]",
) -> None:
    """Worker bound to a single device that evaluates its assigned jobs sequentially."""

    if not jobs:
        return

    # Capture Python-level crash diagnostics (e.g., SIGSEGV, aborts) into a file
    # under the run directory. This does not catch SIGKILL/OOM, but helps with
    # native crashes that otherwise leave no traceback in the main log.
    try:
        import faulthandler
        import os  # local import to keep worker self-contained

        first_job = jobs[0]
        run_dir = str(first_job[5])
        device_str = str(first_job[3])
        crash_path = os.path.join(run_dir, f"device_worker_{device_str.replace(':', '_')}_{os.getpid()}.fatal.log")
        # Keep the file handle open for the lifetime of the worker process so
        # faulthandler can write into it upon a fatal error.
        faulthandler.enable(
            file=open(crash_path, "w", encoding="utf-8"),  # noqa: SIM115
            all_threads=True,
        )
    except Exception:  # noqa: BLE001
        pass

    # Best-effort debug logging: print which device this worker is bound to
    # and which candidates it will evaluate.
    try:
        import os  # local import to keep worker self-contained

        first_job = jobs[0]
        device_str = str(first_job[3])
        job_tags = [(int(j[6]), int(j[7])) for j in jobs]  # (generation, index)
        print(
            f"[free_loss_eoh][device_worker] pid={os.getpid()} device={device_str} "
            f"jobs={job_tags}",
            flush=True,
        )
    except Exception:  # noqa: BLE001
        pass

    for job in jobs:
        idx, fitness = _worker_evaluate_candidate(job)
        result_queue.put((idx, fitness))


def _format_exitcode(exitcode: int | None) -> str:
    if exitcode is None:
        return "running"
    if exitcode == 0:
        return "ok(0)"
    # On POSIX, multiprocessing uses negative values for signals.
    if exitcode < 0:
        return f"signal({-exitcode})"
    return f"code({exitcode})"


def _timestamp_dir(root: str) -> str:
    ts = time.strftime("%Y%m%d-%H%M%S")
    path = os.path.join(root, ts)
    os.makedirs(path, exist_ok=True)
    return path


@contextmanager
def _capture_logs_to_file(path: str) -> Iterator[None]:
    root_logger = logging.getLogger()
    fmt = logging.Formatter("[%(asctime)s] %(levelname)s:%(name)s: %(message)s")
    handler = logging.FileHandler(path, mode="w", encoding="utf-8")
    handler.setLevel(logging.INFO)
    handler.setFormatter(fmt)
    root_logger.addHandler(handler)
    try:
        yield
    finally:
        try:
            root_logger.removeHandler(handler)
        finally:
            handler.close()


def _dump_jsonl(path: str, records: List[Dict[str, Any]]) -> None:
    with open(path, "w", encoding="utf-8") as f:
        for rec in records:
            # Use UTF-8 and allow non-ASCII characters for readability.
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")


def _append_jsonl(path: str, records: List[Dict[str, Any]]) -> None:
    if not records:
        return
    with open(path, "a", encoding="utf-8") as f:
        for rec in records:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")


def _atomic_write_json(path: str, payload: Dict[str, Any]) -> None:
    tmp = f"{path}.tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(payload, f, indent=2, ensure_ascii=False)
    os.replace(tmp, path)


def _b64_pickle(obj: Any) -> str:
    return base64.b64encode(pickle.dumps(obj)).decode("ascii")


def _unb64_pickle(data: str) -> Any:
    return pickle.loads(base64.b64decode(data.encode("ascii")))


def _checkpoint_path(run_dir: str) -> str:
    return os.path.join(run_dir, "checkpoint.json")


def _save_checkpoint(run_dir: str, state: Dict[str, Any]) -> None:
    state = dict(state)
    state["schema_version"] = 1
    state["saved_at"] = time.strftime("%Y-%m-%d %H:%M:%S")
    _atomic_write_json(_checkpoint_path(run_dir), state)


def _load_checkpoint(run_dir: str) -> Dict[str, Any]:
    path = _checkpoint_path(run_dir)
    with open(path, "r", encoding="utf-8") as f:
        state = json.load(f)
    if not isinstance(state, dict):
        raise ValueError(f"Invalid checkpoint format: {path}")
    return state


def evaluate_po_baseline(
    cfg: HighFidelityConfig,
    *,
    early_eval_steps: int | None = None,
) -> Dict[str, Any]:
    """Short-run HF-style evaluation using the RL4CO po_loss baseline."""
    backend = str(getattr(cfg, "backend", "rl4co") or "rl4co").strip().lower()
    if backend != "rl4co":
        raise NotImplementedError(
            "PTP POMO baseline training has been removed; only backend='rl4co' is supported."
        )
    return evaluate_po_baseline_rl4co(cfg, early_eval_steps=early_eval_steps)


def run_free_loss_eoh(
    config_path: str,
    *,
    resume_dir: str | None = None,
    **overrides: Any,
) -> None:
    with open(config_path, "r", encoding="utf-8") as f:
        cfg_yaml = yaml.safe_load(f) or {}

    cfg_yaml.update({k: v for k, v in overrides.items() if v is not None})

    LOGGER.info("Starting free loss EoH search with config=%s", config_path)

    resume_state: Dict[str, Any] | None = None
    run_dir: str | None = None
    if resume_dir:
        run_dir = os.path.abspath(str(resume_dir))
        if not os.path.isdir(run_dir):
            raise FileNotFoundError(f"resume_dir does not exist: {run_dir}")
        resume_state = _load_checkpoint(run_dir)
        seed_from_ckpt = resume_state.get("seed")
        if seed_from_ckpt is not None:
            cfg_yaml["seed"] = int(seed_from_ckpt)
        LOGGER.info("Resuming search from run directory: %s", run_dir)

    seed = int(cfg_yaml.get("seed", 0))
    _set_seed(seed)

    generations = int(cfg_yaml.get("generations", 1))
    population_size = int(cfg_yaml.get("population_size", 8))
    elite_size = int(cfg_yaml.get("elite_size", 4))
    init_llm = int(cfg_yaml.get("init_llm", 4))

    hf_epochs = int(cfg_yaml.get("hf_epochs", 0) or 0)
    hf_instances_per_epoch = int(cfg_yaml.get("hf_instances_per_epoch", 0) or 0)
    pomo_size_yaml = cfg_yaml.get("pomo_size", None)

    backend = str(cfg_yaml.get("backend", "ptp") or "ptp").strip().lower()
    env_name = cfg_yaml.get("env_name") or cfg_yaml.get("problem", "tsp")
    generator_params = cfg_yaml.get("generator_params", {}) or {}
    env_kwargs = cfg_yaml.get("env_kwargs", {}) or {}
    policy_name = cfg_yaml.get("policy_name", "") or ""
    policy_kwargs = cfg_yaml.get("policy_kwargs", {}) or {}
    rollout_strategy = cfg_yaml.get("rollout_strategy", "auto")
    objective_sign = cfg_yaml.get("objective_sign", "neg_reward")

    hf_cfg = HighFidelityConfig(
        problem=cfg_yaml.get("problem", "tsp"),
        backend=backend,
        env_name=str(env_name),
        env_kwargs=dict(env_kwargs),
        generator_params=dict(generator_params),
        policy_name=str(policy_name),
        policy_kwargs=dict(policy_kwargs),
        rollout_strategy=str(rollout_strategy),
        objective_sign=str(objective_sign),
        hf_steps=int(cfg_yaml.get("f1_steps", 32)),
        hf_epochs=hf_epochs,
        hf_instances_per_epoch=hf_instances_per_epoch,
        train_problem_size=int(cfg_yaml.get("train_problem_size", 20)),
        valid_problem_sizes=tuple(int(v) for v in cfg_yaml.get("valid_problem_sizes", [100])),
        train_batch_size=int(cfg_yaml.get("train_batch_size", 64)),
        pomo_size=int(pomo_size_yaml) if pomo_size_yaml is not None else None,
        learning_rate=float(cfg_yaml.get("learning_rate", 3e-4)),
        weight_decay=float(cfg_yaml.get("weight_decay", 1e-6)),
        alpha=float(cfg_yaml.get("alpha", 0.05)),
        device=str(cfg_yaml.get("device", "cuda")),
        seed=seed,
        num_validation_episodes=int(cfg_yaml.get("num_validation_episodes", 128)),
        validation_batch_size=int(cfg_yaml.get("validation_batch_size", 64)),
        generalization_penalty_weight=float(cfg_yaml.get("generalization_penalty_weight", 1.0)),
        size_aggregation=str(cfg_yaml.get("size_aggregation", "cvar")),
        size_cvar_alpha=float(cfg_yaml.get("size_cvar_alpha", 0.2)),
        pool_version=str(cfg_yaml.get("pool_version", "v0")),
    )

    free_cfg = FreeLossFidelityConfig(
        hf=hf_cfg,
        f1_steps=int(cfg_yaml.get("f1_steps", 32)),
        f2_steps=int(cfg_yaml.get("f2_steps", 0)),
        f3_enabled=bool(cfg_yaml.get("f3_enabled", False)),
        baseline_epoch_violation_weight=float(
            cfg_yaml.get("baseline_epoch_violation_weight", 1.0)
        ),
    )
    hf_cfg_dict: Dict[str, Any] = dict(hf_cfg.__dict__)
    free_cfg_dict: Dict[str, Any] = {
        "f1_steps": free_cfg.f1_steps,
        "f2_steps": free_cfg.f2_steps,
        "f3_enabled": free_cfg.f3_enabled,
        "baseline_epoch_violation_weight": free_cfg.baseline_epoch_violation_weight,
    }

    early_eval_steps = _compute_early_eval_steps(cfg_yaml, hf_cfg)
    baseline_hf_score: float | None = None
    baseline_early_valid: float | None = None
    baseline_epoch_objectives: List[float] | None = None
    burn_in_objectives: List[Dict[str, Any]] = []
    diversity_archive: List[Dict[str, Any]] = []
    diverse_elites: List[Dict[str, Any]] = []
    seen_signatures: set[str] = set()

    out_root = cfg_yaml.get("output_root", "runs/free_loss_discovery")
    if run_dir is None:
        run_dir = _timestamp_dir(out_root)
    LOGGER.info("Run directory: %s", os.path.abspath(run_dir))

    candidates_jsonl_path = os.path.join(run_dir, "candidates.jsonl")
    gates_jsonl_path = os.path.join(run_dir, "gate_reports.jsonl")
    fitness_jsonl_path = os.path.join(run_dir, "fitness_scores.jsonl")

    if resume_state is None:
        # Fresh run: truncate/initialize JSONL logs.
        for path in (candidates_jsonl_path, gates_jsonl_path, fitness_jsonl_path):
            with open(path, "w", encoding="utf-8"):
                pass

    # Baseline: evaluate the original POMO po_loss once, using the same HF
    # configuration. This provides a reference score before searching over
    # free-form preference losses.
    baseline: Dict[str, Any] | None = None
    baseline_json_path = os.path.join(run_dir, "baseline.json")
    if os.path.isfile(baseline_json_path):
        try:
            with open(baseline_json_path, "r", encoding="utf-8") as f:
                baseline = json.load(f)
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("Failed to load baseline.json (%s): %s", baseline_json_path, exc)
            baseline = None
    elif resume_state is not None:
        cand = resume_state.get("baseline")
        if isinstance(cand, dict):
            baseline = dict(cand)

    if baseline is None:
        try:
            baseline_log_path = os.path.join(run_dir, "baseline_po_loss.log")
            with _capture_logs_to_file(baseline_log_path):
                LOGGER.info(
                    "Saving baseline training log to %s", os.path.abspath(baseline_log_path)
                )
                baseline = evaluate_po_baseline(hf_cfg, early_eval_steps=early_eval_steps)
            _atomic_write_json(baseline_json_path, dict(baseline))
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("Failed to evaluate baseline po_loss: %s", exc)
            baseline = None

    if baseline is not None:
        baseline_hf_score = float(baseline.get("fitness_score", baseline["hf_score"]))
        baseline_early_valid = float(
            baseline.get("early_validation_objective", baseline["validation_objective"])
        )
        baseline_epoch_objectives = baseline.get("epoch_eval", {}).get("objectives")
        if baseline_epoch_objectives:
            baseline_epoch_objectives = [float(v) for v in baseline_epoch_objectives]
        burn_in_objectives.append(
            {
                "name": "po_loss_baseline",
                "type": "handcrafted_loss",
                "description": "Original POMO policy optimization loss (po_loss).",
                "hf_like_score": float(baseline.get("fitness_score", baseline["hf_score"])),
                "fitness_score": float(baseline.get("fitness_score", baseline["hf_score"])),
                "validation_objective": float(baseline["validation_objective"]),
                "generalization_penalty": float(baseline["generalization_penalty"]),
                "early_validation_objective": baseline.get("early_validation_objective"),
                "early_eval_steps": baseline.get("early_eval_steps"),
                "epoch_objective_mean": baseline.get("epoch_eval", {}).get("objective_mean"),
                "epoch_validation_objectives": baseline.get("epoch_eval", {}).get("objectives"),
                "epoch_steps_per_epoch": baseline.get("epoch_eval", {}).get("steps_per_epoch"),
            }
        )
        LOGGER.info(
            "Baseline po_loss: hf_score=%.6f, fitness_score=%.6f, validation_objective=%.6f, gen_penalty=%.6f",
            float(baseline["hf_score"]),
            float(baseline.get("fitness_score", baseline["hf_score"])),
            float(baseline["validation_objective"]),
            float(baseline["generalization_penalty"]),
        )

    if resume_state is not None:
        burn_in_loaded = resume_state.get("burn_in_objectives")
        if isinstance(burn_in_loaded, list):
            burn_in_objectives = [dict(v) for v in burn_in_loaded if isinstance(v, dict)]
        diversity_loaded = resume_state.get("diversity_archive")
        if isinstance(diversity_loaded, list):
            diversity_archive = [dict(v) for v in diversity_loaded if isinstance(v, dict)]
        seen_loaded = resume_state.get("seen_signatures")
        if isinstance(seen_loaded, list):
            seen_signatures = {str(v) for v in seen_loaded}

    operator_whitelist = list(cfg_yaml.get("operator_whitelist", []))
    prompts = cfg_yaml.get("prompts", {}) or {}
    gen_prompt = prompts.get("generation")
    crossover_prompt = prompts.get("crossover")
    e2_prompt = prompts.get("e2")
    mutation_prompt = prompts.get("mutation")
    m2_prompt = prompts.get("m2")
    m3_prompt = prompts.get("m3")
    repair_prompt = prompts.get("repair")
    directed_repair_prompt = prompts.get("directed_repair")
    expects_repair_prompt = prompts.get("expects_repair")
    max_resample_rounds = int(cfg_yaml.get("max_resample_rounds", 1) or 0)
    burn_in_objectives_auto = bool(cfg_yaml.get("burn_in_objectives_auto", True))

    directed_repair_enabled = bool(cfg_yaml.get("directed_repair_enabled", False)) and bool(directed_repair_prompt)
    directed_repair_max_parents = int(cfg_yaml.get("directed_repair_max_parents_per_generation", 0) or 0)
    directed_repair_children_per_strategy = int(cfg_yaml.get("directed_repair_children_per_strategy", 1) or 1)
    directed_repair_strategies = cfg_yaml.get("directed_repair_strategies") or ["e1", "e2", "m1", "m2"]
    directed_repair_strategies = [str(s).strip().lower() for s in directed_repair_strategies if str(s).strip()]

    pref_semantic_gate_enabled = bool(cfg_yaml.get("pref_semantic_gate_enabled", True))
    pref_semantic_trials = int(cfg_yaml.get("pref_semantic_trials", 6))
    pref_semantic_batch_size = int(cfg_yaml.get("pref_semantic_batch_size", 128))
    pref_semantic_min_pass_rate = float(cfg_yaml.get("pref_semantic_min_pass_rate", 0.8))
    pref_semantic_swap_tolerance = float(cfg_yaml.get("pref_semantic_swap_tolerance", 1e-3))
    pref_semantic_gap_min_ratio = float(cfg_yaml.get("pref_semantic_gap_min_ratio", 0.9))

    hidden_dynamic_gates_enabled = bool(cfg_yaml.get("hidden_dynamic_gates_enabled", False))

    behavior_deltas = cfg_yaml.get("novelty_behavior_deltas") or [-10, -5, -2, -1, 0, 1, 2, 5, 10]
    behavior_deltas = [float(v) for v in behavior_deltas]
    novelty_k = int(cfg_yaml.get("novelty_k", 5))
    novelty_ops_weight = float(cfg_yaml.get("novelty_ops_weight", 1.0))
    novelty_hparam_weight = float(cfg_yaml.get("novelty_hparam_weight", 0.5))
    novelty_behavior_weight = float(cfg_yaml.get("novelty_behavior_weight", 1.0))
    novelty_thought_weight = float(cfg_yaml.get("novelty_thought_weight", 0.25))
    diversity_archive_size = int(cfg_yaml.get("diversity_archive_size", 32))

    elites: List[Dict[str, Any]] = []
    gen_start = 0

    gate_recent_maxlen = int(cfg_yaml.get("gate_recent_maxlen", 200) or 200)
    gates_recent: deque[Dict[str, Any]] = deque(maxlen=max(1, gate_recent_maxlen))
    gate_failure_stats: Dict[str, int] = {}

    max_repair_rounds = int(cfg_yaml.get("max_repair_rounds", 0) or 0)
    LOGGER.info(
        "Gate retries: max_repair_rounds=%d (LLM repairs), max_resample_rounds=%d (drop+resample)",
        max_repair_rounds,
        max_resample_rounds,
    )

    if burn_in_objectives_auto and resume_state is None:
        burn_in_objectives.extend(_build_auto_seed_objectives())

    def _restore_pool(raw: Any) -> List[Dict[str, Any]]:
        if not isinstance(raw, list):
            return []
        restored: List[Dict[str, Any]] = []
        for item in raw:
            if not isinstance(item, dict):
                continue
            entry = dict(item)
            ir_payload = entry.get("ir")
            if isinstance(ir_payload, dict):
                try:
                    entry["ir"] = ir_from_json(ir_payload)
                except Exception:  # noqa: BLE001
                    continue
            restored.append(entry)
        return restored

    rng = random.Random()
    best_hf_so_far = float("inf")
    stalled_gens = 0
    prev_dynamic_fail_rate = 0.0
    if resume_state is not None:
        gen_start = int(resume_state.get("next_generation", 0) or 0)
        diverse_elites = _restore_pool(resume_state.get("diverse_elites"))
        elites = _restore_pool(resume_state.get("elites"))

        gate_failure_loaded = resume_state.get("gate_failure_stats")
        if isinstance(gate_failure_loaded, dict):
            gate_failure_stats = {str(k): int(v) for k, v in gate_failure_loaded.items()}

        recent_loaded = resume_state.get("gates_recent")
        if isinstance(recent_loaded, list):
            for item in recent_loaded:
                if isinstance(item, dict):
                    gates_recent.append(dict(item))

        best_hf_so_far = float(resume_state.get("best_hf_so_far", float("inf")))
        stalled_gens = int(resume_state.get("stalled_gens", 0) or 0)
        prev_dynamic_fail_rate = float(resume_state.get("prev_dynamic_fail_rate", 0.0) or 0.0)

        rng_state_b64 = resume_state.get("rng_state_b64")
        if isinstance(rng_state_b64, str) and rng_state_b64:
            try:
                rng.setstate(_unb64_pickle(rng_state_b64))
            except Exception:  # noqa: BLE001
                rng.seed(seed)
        else:
            rng.seed(seed)
    else:
        rng.seed(seed)

    def _maybe_repair_expects(ir: FreeLossIR) -> FreeLossIR:
        if not expects_repair_prompt:
            return ir
        expects = ir.implementation_hint.expects or []
        # Only call the repair prompt when we already have a list; this
        # is meant to normalize names, not to infer them from scratch.
        if not isinstance(expects, (list, tuple)) or not expects:
            return ir
        try:
            return repair_expects_with_prompt(expects_repair_prompt, ir)
        except Exception as exc:  # noqa: BLE001
            LOGGER.warning("Failed to repair expects via LLM: %s", exc)
            return ir

    def _weighted_choice(options: List[Tuple[str, float]]) -> str:
        total = sum(max(0.0, float(w)) for _, w in options)
        if total <= 0.0:
            return options[0][0]
        r = rng.random() * total
        acc = 0.0
        for name, w in options:
            acc += max(0.0, float(w))
            if r <= acc:
                return name
        return options[-1][0]

    def _rank_weighted_sample(entries: List[Dict[str, Any]], k: int) -> List[Dict[str, Any]]:
        if not entries or k <= 0:
            return []
        k = min(k, len(entries))
        ranks = _pareto_ranks(entries)
        rank_bias = float(cfg_yaml.get("parent_sampling_rank_bias", 1.0))
        weights = [1.0 / (float(r) + rank_bias) for r in ranks]
        chosen: List[Dict[str, Any]] = []
        available = list(range(len(entries)))
        while available and len(chosen) < k:
            total_w = sum(weights[i] for i in available)
            if total_w <= 0.0:
                idx = rng.choice(available)
            else:
                r = rng.random() * total_w
                acc = 0.0
                idx = available[-1]
                for i in available:
                    acc += weights[i]
                    if r <= acc:
                        idx = i
                        break
            chosen.append(entries[idx])
            available.remove(idx)
        return chosen

    def _choose_llm_op(*, gen: int, parent_pool_size: int, global_feedback: Dict[str, Any]) -> str:
        if gen == 0 or parent_pool_size <= 0:
            return "E1_GENERATE"

        early_cutoff = max(1, int(round(generations * 0.3)))
        late_cutoff = max(1, int(round(generations * 0.7)))

        if stalled_gens >= int(cfg_yaml.get("scheduler_stall_window", 2) or 2):
            if e2_prompt and parent_pool_size >= 2:
                return "E2"

        if prev_dynamic_fail_rate >= float(cfg_yaml.get("scheduler_fail_rate_high", 0.6)) and m3_prompt:
            return "M3"

        suggested_mode = str(global_feedback.get("suggested_mode") or "explore").lower()
        if gen < early_cutoff:
            # Early: expand structural search space via E1/E2.
            options: List[Tuple[str, float]] = [
                ("E2", 0.65 if suggested_mode != "refine" else 0.45),
                ("E1", 0.35),
            ]
        elif gen >= late_cutoff:
            # Late: refine via M2/M1, with occasional recombination.
            options = [
                ("M2", 0.50 if suggested_mode == "refine" else 0.40),
                ("M1", 0.30),
                ("E2", 0.20),
            ]
        else:
            # Mid: balance recombination and local refinement.
            options = [
                ("M2", 0.40 if suggested_mode == "refine" else 0.30),
                ("M1", 0.35),
                ("E2", 0.25),
            ]

        filtered: List[Tuple[str, float]] = []
        for name, w in options:
            if name == "E2" and (not e2_prompt or parent_pool_size < 2):
                continue
            if name == "E1" and (not crossover_prompt or parent_pool_size < 2):
                continue
            if name == "M1" and (not mutation_prompt or parent_pool_size < 1):
                continue
            if name == "M2" and (not m2_prompt or parent_pool_size < 1):
                continue
            if name == "M3" and (not m3_prompt or parent_pool_size < 1):
                continue
            filtered.append((name, w))

        if not filtered:
            if mutation_prompt and parent_pool_size >= 1:
                return "M1"
            if crossover_prompt and parent_pool_size >= 2:
                return "E1"
            return "E1_GENERATE"

        return _weighted_choice(filtered)

    def _sample_candidate(
        *,
        gen: int,
        parent_pool: List[Dict[str, Any]],
        global_feedback: Dict[str, Any],
    ) -> Tuple[FreeLossIR, str]:
        op = _choose_llm_op(gen=gen, parent_pool_size=len(parent_pool), global_feedback=global_feedback)

        if op == "E2" and e2_prompt and len(parent_pool) >= 2:
            parent_count = int(cfg_yaml.get("parent_count_e2", 5) or 5)
            chosen = _rank_weighted_sample(parent_pool, min(parent_count, len(parent_pool)))
            parent_irs = [p["ir"] for p in chosen]
            return (
                e2_free_loss(
                    e2_prompt,
                    parent_irs,
                    parents_fitness=[p["fitness"] for p in chosen],
                    global_feedback=global_feedback,
                ),
                op,
            )

        if op == "E1" and crossover_prompt and len(parent_pool) >= 2:
            chosen = _rank_weighted_sample(parent_pool, 2)
            parent_irs = [p["ir"] for p in chosen]
            return (
                crossover_free_loss(
                    crossover_prompt,
                    parent_irs,
                    parents_fitness=[p["fitness"] for p in chosen],
                    global_feedback=global_feedback,
                ),
                op,
            )

        if op == "M2" and m2_prompt and parent_pool:
            parent = _select_parents(parent_pool, 1)[0]
            return (
                m2_tune_hparams(
                    m2_prompt,
                    parent["ir"],
                    parent_fitness=parent["fitness"],
                    global_feedback=global_feedback,
                ),
                op,
            )

        if op == "M3" and m3_prompt and parent_pool:
            parent = _select_parents(parent_pool, 1)[0]
            failure_context = {
                "stage": "scheduler",
                "code": "E_HIGH_FAILURE_RATE" if prev_dynamic_fail_rate > 0 else "E_SCHEDULER_M3",
                "message": "Simplify for stability and preference semantics.",
                "extra": {
                    "prev_dynamic_fail_rate": prev_dynamic_fail_rate,
                },
            }
            return (
                m3_simplify_loss(
                    m3_prompt,
                    parent["ir"],
                    failure_context,
                    global_feedback=global_feedback,
                ),
                op,
            )

        if op == "M1" and mutation_prompt and parent_pool:
            parent = _select_parents(parent_pool, 1)[0]
            return (
                mutate_free_loss(
                    mutation_prompt,
                    parent["ir"],
                    parent_fitness=parent["fitness"],
                    global_feedback=global_feedback,
                ),
                op,
            )

        return (
            generate_free_loss_candidate(
                gen_prompt,
                operator_whitelist=operator_whitelist,
                global_feedback=global_feedback,
            ),
            "E1_GENERATE",
        )

    def _should_resample_dynamic(reason: str) -> bool:
        msg = (reason or "").lower()
        return (
            "missing_dependency" in msg
            or "missing_batch_key" in msg
            or "extra_batch_key" in msg
            or "invalid_expects" in msg
            or "missing_expects" in msg
            or "unsupported_expects" in msg
        )

    def _extract_counterexamples_from_trace(trace: Any) -> List[Dict[str, Any]]:
        if not isinstance(trace, dict):
            return []
        raw = trace.get("counterexamples")
        if not isinstance(raw, list):
            return []
        out: List[Dict[str, Any]] = []
        for item in raw:
            if isinstance(item, dict):
                out.append(dict(item))
        return out

    def _directed_repair_children(
        parent_ir: FreeLossIR,
        *,
        strategy: str,
        gate_spec: Dict[str, Any],
        fail_report: Dict[str, Any],
        counterexamples: List[Dict[str, Any]],
        global_feedback: Dict[str, Any],
    ) -> List[FreeLossIR]:
        if not directed_repair_enabled or not directed_repair_prompt:
            return []

        allowed_keys = list(supported_keys_for_mode(parent_ir.implementation_hint.mode))
        children: List[FreeLossIR] = []
        for _ in range(max(1, int(directed_repair_children_per_strategy))):
            child = repair_from_gate_failure(
                directed_repair_prompt,
                parent_ir,
                strategy=strategy,
                gate_spec=gate_spec,
                fail_report=fail_report,
                counterexamples=counterexamples,
                allowed_keys=allowed_keys,
                global_feedback=global_feedback,
            )
            children.append(child)
        return children

    pending_candidates: List[Dict[str, Any]] = []
    pending_fitness: List[Dict[str, Any]] = []
    pending_gates: List[Dict[str, Any]] = []

    def _flush_jsonl_logs() -> None:
        _append_jsonl(candidates_jsonl_path, pending_candidates)
        _append_jsonl(gates_jsonl_path, pending_gates)
        _append_jsonl(fitness_jsonl_path, pending_fitness)
        pending_candidates.clear()
        pending_gates.clear()
        pending_fitness.clear()

    def _record_gate_entry(entry: Dict[str, Any]) -> None:
        pending_gates.append(entry)
        is_failure = (not entry.get("static_ok", True)) or (entry.get("dynamic_ok") is False)
        if not is_failure:
            return
        stub = {
            "generation": int(entry.get("generation", -1)),
            "index": int(entry.get("index", -1)),
            "attempt": int(entry.get("attempt", 0)),
            "llm_op": entry.get("llm_op"),
            "static_ok": bool(entry.get("static_ok", True)),
            "dynamic_ok": entry.get("dynamic_ok"),
            "static_error_code": entry.get("static_error_code"),
            "dynamic_error_code": entry.get("dynamic_error_code"),
            "static_reason": entry.get("static_reason"),
            "dynamic_reason": entry.get("dynamic_reason"),
        }
        gates_recent.append(stub)
        for key in ("static_error_code", "dynamic_error_code"):
            code = entry.get(key)
            if code:
                gate_failure_stats[str(code)] = gate_failure_stats.get(str(code), 0) + 1

    def _serialize_pool(entries: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        out: List[Dict[str, Any]] = []
        for item in entries:
            if not isinstance(item, dict):
                continue
            entry = dict(item)
            ir_val = entry.get("ir")
            if isinstance(ir_val, FreeLossIR):
                entry["ir"] = asdict(ir_val)
            out.append(entry)
        return out

    def _checkpoint_state(next_generation: int) -> Dict[str, Any]:
        state: Dict[str, Any] = {
            "config_path": os.path.abspath(config_path),
            "seed": int(seed),
            "next_generation": int(next_generation),
            "rng_state_b64": _b64_pickle(rng.getstate()),
            "baseline": dict(baseline) if baseline is not None else None,
            "baseline_hf_score": baseline_hf_score,
            "baseline_early_valid": baseline_early_valid,
            "baseline_epoch_objectives": baseline_epoch_objectives,
            "burn_in_objectives": burn_in_objectives,
            "diversity_archive": diversity_archive[-diversity_archive_size:],
            "diverse_elites": _serialize_pool(diverse_elites),
            "elites": _serialize_pool(elites),
            "seen_signatures": sorted(seen_signatures),
            "best_hf_so_far": float(best_hf_so_far),
            "stalled_gens": int(stalled_gens),
            "prev_dynamic_fail_rate": float(prev_dynamic_fail_rate),
            "gate_failure_stats": gate_failure_stats,
            "gates_recent": list(gates_recent),
        }
        return state

    def _write_best_candidate_snapshot() -> None:
        if not elites:
            return
        best = sorted(elites, key=lambda e: float(e["fitness"]["hf_like_score"]))[0]
        best_serializable = dict(best)
        ir_value = best_serializable.get("ir")
        if isinstance(ir_value, FreeLossIR):
            best_serializable["ir"] = asdict(ir_value)
        best_path = os.path.join(run_dir, "best_candidate.json")
        with open(best_path, "w", encoding="utf-8") as f:
            json.dump(best_serializable, f, indent=2, ensure_ascii=False)

    # Ensure we always have a checkpoint on disk before long-running work.
    _save_checkpoint(run_dir, _checkpoint_state(gen_start))
    _write_best_candidate_snapshot()

    if gen_start >= generations:
        LOGGER.info(
            "Resume point is at generation %d, but generations=%d; nothing to do.",
            gen_start,
            generations,
        )
        _write_run_analysis(
            run_dir,
            baseline_hf_score=baseline_hf_score,
            generations=generations,
            population_size=population_size,
            gate_failure_stats=gate_failure_stats,
            elites=elites,
        )
        return

    for gen in range(gen_start, generations):
        LOGGER.info("=== Generation %d/%d ===", gen, generations - 1)
        global_feedback = _build_global_feedback(
            elites=elites,
            gates_log=list(gates_recent),
            burn_in_objectives=burn_in_objectives,
            baseline_hf_score=baseline_hf_score,
            diversity_archive=diversity_archive,
        )
        population: List[FreeLossIR] = []
        sample_ops: List[str] = []
        parent_pool: List[Dict[str, Any]] = []
        if gen == 0:
            LOGGER.info("Generating initial population with %d LLM candidates", init_llm)
            for _ in range(init_llm):
                ir, op = _sample_candidate(gen=gen, parent_pool=parent_pool, global_feedback=global_feedback)
                population.append(_maybe_repair_expects(ir))
                sample_ops.append(op)
        else:
            parent_pool = diverse_elites if diverse_elites else elites
            LOGGER.info(
                "Generating population via E1/E2/M1/M2/M3: size=%d, elite_size=%d, parent_pool=%d",
                population_size,
                elite_size,
                len(parent_pool),
            )
            for _ in range(population_size):
                ir, op = _sample_candidate(gen=gen, parent_pool=parent_pool, global_feedback=global_feedback)
                population.append(_maybe_repair_expects(ir))
                sample_ops.append(op)

        LOGGER.info("Population size for generation %d: %d", gen, len(population))
        gen_elites: List[Dict[str, Any]] = []

        static_fail = 0
        dynamic_fail = 0
        evaluated = 0

        directed_repair_parents_used = 0
        next_child_index = len(population)
        directed_repair_parent_signatures: set[str] = set()

        # Collect candidates that pass all gates and evaluate them in
        # parallel across available devices.
        eval_jobs: List[
            Tuple[
                Dict[str, Any],
                Dict[str, Any],
                Dict[str, Any],
                str,
                List[str],
                str,
                int,
                int,
                float | None,
                List[float] | None,
                int,
            ]
        ] = []
        eval_candidates: Dict[int, FreeLossIR] = {}

        for idx, original_ir in enumerate(population):
            ir = original_ir
            llm_op = sample_ops[idx] if idx < len(sample_ops) else ""
            resample_attempts = 0
            while True:
                resampled = False
                for attempt in range(max_repair_rounds + 1):
                    signature = _candidate_signature(ir)
                    static_res: StaticGateResult
                    if signature in seen_signatures:
                        static_res = StaticGateResult(ok=False, reason="duplicate_candidate")
                    else:
                        static_res = run_static_gates(ir, operator_whitelist=operator_whitelist)
                    static_code = "" if static_res.ok else _classify_failure("static", static_res.reason)
                    gate_entry: Dict[str, Any] = {
                        "generation": gen,
                        "index": idx,
                        "attempt": attempt,
                        "llm_op": llm_op,
                        "ir": asdict(ir),
                        "static_ok": static_res.ok,
                        "static_reason": static_res.reason,
                        "static_error_code": static_code,
                    }

                    if not static_res.ok:
                        if attempt < max_repair_rounds and repair_prompt:
                            try:
                                failure_payload = _build_failure_payload(
                                    generation=gen,
                                    index=idx,
                                    attempt=attempt,
                                    stage="static_gate",
                                    code=static_code,
                                    message=static_res.reason,
                                    extra=None,
                                )
                                ir = repair_free_loss(repair_prompt, ir, failure_payload)
                                continue
                            except Exception as exc:  # noqa: BLE001
                                LOGGER.warning(
                                    "Failed to repair static gate error for gen=%d, idx=%d: %s",
                                    gen,
                                    idx,
                                    exc,
                                )
                        static_fail += 1
                        _record_gate_entry(gate_entry)
                        break

                    try:
                        compiled = compile_free_loss_candidate(
                            ir,
                            operator_whitelist=operator_whitelist,
                        )
                    except CompileError as exc:
                        compile_code = _classify_failure("compile", str(exc))
                        gate_entry["dynamic_ok"] = False
                        gate_entry["dynamic_reason"] = f"compile_error: {exc}"
                        gate_entry["dynamic_error_code"] = compile_code
                        if attempt < max_repair_rounds and repair_prompt:
                            try:
                                failure_payload = _build_failure_payload(
                                    generation=gen,
                                    index=idx,
                                    attempt=attempt,
                                    stage="compile",
                                    code=compile_code,
                                    message=str(exc),
                                    extra=None,
                                )
                                ir = repair_free_loss(repair_prompt, ir, failure_payload)
                                continue
                            except Exception as exc2:  # noqa: BLE001
                                LOGGER.warning(
                                    "Failed to repair compile error for gen=%d, idx=%d: %s",
                                    gen,
                                    idx,
                                    exc2,
                                )
                        _record_gate_entry(gate_entry)
                        break


                    mode = str(getattr(ir.implementation_hint, "mode", "pairwise") or "pairwise").strip().lower()
                    expects = [str(x) for x in (ir.implementation_hint.expects or [])]

                    def _make_dummy_inputs(*, variant: str) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:
                        if mode == "setwise":
                            from fitness.co_features import (  # local import to keep gates lightweight
                                build_model_output,
                            )

                            if variant == "hidden":
                                objective = torch.rand(4, 8) * 10.0
                                log_prob = torch.rand(4, 8) * -12.0
                            else:
                                objective = torch.rand(4, 8)
                                log_prob = torch.rand(4, 8) * -8.0
                            model_out, _ = build_model_output(objective=objective, log_prob=log_prob)
                            dummy_out = {k: model_out[k] for k in expects if k in model_out}
                            return {}, dummy_out

                        if variant == "hidden":
                            cost_a = torch.rand(16)
                            gap = torch.rand(16) * 3.0
                            cost_b = cost_a + gap
                            log_prob_l = torch.empty(16).uniform_(-30.0, 0.0)
                            log_prob_w = log_prob_l + torch.empty(16).uniform_(-10.0, 10.0)
                            delta_z = gap * 4.0
                        else:
                            cost_a = torch.zeros(16)
                            cost_b = torch.ones(16)
                            log_prob_w = torch.zeros(16)
                            log_prob_l = torch.zeros(16)
                            delta_z = torch.ones(16)

                        full_dummy = {
                            "cost_a": cost_a,
                            "cost_b": cost_b,
                            "log_prob_w": log_prob_w,
                            "log_prob_l": log_prob_l,
                            "delta_z": delta_z,
                            "delta_rank": torch.ones(16),
                            "delta_regret": torch.ones(16),
                            "weight": torch.ones(16),
                        }
                        dummy_batch_local = {k: full_dummy[k] for k in expects if k in full_dummy}
                        if not dummy_batch_local:
                            dummy_batch_local = dict(full_dummy)
                        return dummy_batch_local, {}

                    dummy_batch_vis, dummy_out_vis = _make_dummy_inputs(variant="visible")
                    dyn_vis = run_dynamic_gates(
                        compiled,
                        batch=dummy_batch_vis,
                        model_output=dummy_out_vis,
                        model=model,
                        grad_norm_max=float(cfg_yaml.get("grad_norm_max", 10.0)),
                        loss_soft_min=float(cfg_yaml.get("loss_soft_min", -5.0)),
                        loss_soft_max=float(cfg_yaml.get("loss_soft_max", 5.0)),
                    )
                    dyn_hid: DynamicGateResult | None = None
                    if dyn_vis.ok and hidden_dynamic_gates_enabled:
                        dummy_batch_hid, dummy_out_hid = _make_dummy_inputs(variant="hidden")
                        dyn_hid = run_dynamic_gates(
                            compiled,
                            batch=dummy_batch_hid,
                            model_output=dummy_out_hid,
                            model=model,
                            grad_norm_max=float(cfg_yaml.get("grad_norm_max", 10.0)),
                            loss_soft_min=float(cfg_yaml.get("loss_soft_min", -5.0)),
                            loss_soft_max=float(cfg_yaml.get("loss_soft_max", 5.0)),
                        )

                    dyn_res: DynamicGateResult = dyn_vis
                    dyn_ok = bool(dyn_vis.ok) and (True if dyn_hid is None else bool(dyn_hid.ok))
                    dyn_reason = dyn_vis.reason if not dyn_vis.ok else (dyn_hid.reason if dyn_hid is not None and not dyn_hid.ok else "ok")
                    loss_value = dyn_vis.loss_value if not dyn_vis.ok else (dyn_hid.loss_value if dyn_hid is not None and not dyn_hid.ok else dyn_vis.loss_value)
                    grad_norm = dyn_vis.grad_norm if not dyn_vis.ok else (dyn_hid.grad_norm if dyn_hid is not None and not dyn_hid.ok else dyn_vis.grad_norm)
                    gate_entry.update(
                        {
                            "dynamic_ok": dyn_ok,
                            "dynamic_reason": dyn_reason,
                            "loss_value": loss_value,
                            "grad_norm": grad_norm,
                            "dynamic_visible_ok": dyn_vis.ok,
                            "dynamic_visible_reason": dyn_vis.reason,
                            "dynamic_visible_trace": dyn_vis.trace,
                            "dynamic_hidden_ok": None if dyn_hid is None else dyn_hid.ok,
                            "dynamic_hidden_reason": None if dyn_hid is None else dyn_hid.reason,
                            "dynamic_hidden_trace": None if dyn_hid is None else dyn_hid.trace,
                        }
                    )
                    if not dyn_ok:
                        gate_entry["dynamic_error_code"] = _classify_failure("dynamic", dyn_reason)

                    if not dyn_ok:
                        _record_gate_entry(gate_entry)
                        if (
                            (not dyn_vis.ok)
                            and _should_resample_dynamic(dyn_vis.reason)
                            and resample_attempts < max_resample_rounds
                        ):
                            resample_attempts += 1
                            LOGGER.warning(
                                "Dynamic gates failed for gen=%d, idx=%d, name=%s: reason=%s; "
                                "dropping candidate and resampling (resample_round=%d/%d)",
                                gen,
                                idx,
                                ir.name,
                                dyn_vis.reason,
                                resample_attempts,
                                max_resample_rounds,
                            )
                            ir, llm_op = _sample_candidate(
                                gen=gen,
                                parent_pool=parent_pool,
                                global_feedback=global_feedback,
                            )
                            ir = _maybe_repair_expects(ir)
                            resampled = True
                            break

                        # Directed repair (CEGIS-style): if the VISIBLE dynamic gate fails,
                        # treat this candidate as a parent and enqueue multiple children
                        # via e1/e2/m1/m2 rather than discarding immediately.
                        if (
                            attempt < max_repair_rounds
                            and directed_repair_enabled
                            and directed_repair_prompt
                            and (not dyn_vis.ok)
                            and (directed_repair_max_parents <= 0 or directed_repair_parents_used < directed_repair_max_parents)
                        ):
                            parent_sig = _candidate_signature(ir)
                            if parent_sig not in directed_repair_parent_signatures:
                                directed_repair_parent_signatures.add(parent_sig)
                                directed_repair_parents_used += 1

                                gate_spec = {
                                    "gate": "DynamicStability",
                                    "checks": {
                                        "grad_norm_max": float(cfg_yaml.get("grad_norm_max", 10.0)),
                                        "loss_soft_range": [
                                            float(cfg_yaml.get("loss_soft_min", -5.0)),
                                            float(cfg_yaml.get("loss_soft_max", 5.0)),
                                        ],
                                    },
                                }
                                fail_report = {
                                    "failed_gate": "DynamicStability",
                                    "reason": dyn_vis.reason,
                                    "trace": dyn_vis.trace or {},
                                }
                                counterexamples = _extract_counterexamples_from_trace(dyn_vis.trace)

                                LOGGER.warning(
                                    "Directed repair enqueue for gen=%d, idx=%d, name=%s (strategies=%s)",
                                    gen,
                                    idx,
                                    ir.name,
                                    ",".join(directed_repair_strategies),
                                )
                                for strat in directed_repair_strategies:
                                    try:
                                        children = _directed_repair_children(
                                            ir,
                                            strategy=strat,
                                            gate_spec=gate_spec,
                                            fail_report=fail_report,
                                            counterexamples=counterexamples,
                                            global_feedback=global_feedback,
                                        )
                                        for child in children:
                                            # Tag parent linkage for analysis/debugging.
                                            child.name = f"{child.name}_p{idx}"
                                            population.append(child)
                                            sample_ops.append(f"DR_{strat.upper()}")
                                    except Exception as exc:  # noqa: BLE001
                                        LOGGER.warning(
                                            "Directed repair failed for gen=%d, idx=%d, strategy=%s: %s",
                                            gen,
                                            idx,
                                            strat,
                                            exc,
                                        )
                                dynamic_fail += 1
                                break

                        if attempt < max_repair_rounds and (repair_prompt or m3_prompt):
                            LOGGER.warning(
                                "Dynamic gates failed for gen=%d, idx=%d, name=%s: reason=%s, "
                                "loss_value=%s, grad_norm=%s; attempting repair (repair_round=%d/%d)",
                                gen,
                                idx,
                                ir.name,
                                dyn_reason,
                                str(loss_value),
                                str(grad_norm),
                                attempt + 1,
                                max_repair_rounds,
                            )
                            try:
                                failure_payload = _build_failure_payload(
                                    generation=gen,
                                    index=idx,
                                    attempt=attempt,
                                    stage="dynamic_gate",
                                    code=gate_entry.get("dynamic_error_code", "E_DYNAMIC_OTHER"),
                                    message=dyn_reason,
                                    extra={
                                        "loss_value": loss_value,
                                        "grad_norm": grad_norm,
                                        "gate_trace": dyn_vis.trace,
                                    },
                                )

                                m3_codes = {
                                    "E_RUNTIME_NAN_LOSS",
                                    "E_RUNTIME_NAN_GRAD",
                                    "E_GRAD_EXPLODE",
                                    "E_LOSS_OUT_OF_RANGE",
                                    "E_BACKWARD_ERROR",
                                    "E_FORWARD_ERROR",
                                    "E_PREF_SEMANTIC",
                                    "E_DYNAMIC_OTHER",
                                }
                                if m3_prompt and gate_entry.get("dynamic_error_code") in m3_codes:
                                    try:
                                        ir = m3_simplify_loss(
                                            m3_prompt,
                                            ir,
                                            failure_payload,
                                            global_feedback=global_feedback,
                                        )
                                        llm_op = "M3_REPAIR"
                                        continue
                                    except Exception as exc:  # noqa: BLE001
                                        LOGGER.warning(
                                            "Failed to simplify (M3) for gen=%d, idx=%d: %s",
                                            gen,
                                            idx,
                                            exc,
                                        )

                                if repair_prompt:
                                    ir = repair_free_loss(repair_prompt, ir, failure_payload)
                                    llm_op = "REPAIR"
                                    continue
                            except Exception as exc:  # noqa: BLE001
                                LOGGER.warning(
                                    "Failed to repair dynamic gate error for gen=%d, idx=%d: %s",
                                    gen,
                                    idx,
                                    exc,
                                )
                        dynamic_fail += 1
                        LOGGER.warning(
                            "Dynamic gates failed for gen=%d, idx=%d, name=%s: reason=%s, "
                            "loss_value=%s, grad_norm=%s",
                            gen,
                            idx,
                            ir.name,
                            dyn_reason,
                            str(loss_value),
                            str(grad_norm),
                        )
                        break

                    co_gate_enabled = bool(cfg_yaml.get("co_gate_enabled", True))
                    if co_gate_enabled:
                        sens_vis: ObjectiveSensitivityGateResult = run_objective_sensitivity_gate(
                            compiled,
                            min_abs_delta=float(cfg_yaml.get("co_sensitivity_min_abs_delta", 1e-3)),
                            min_rel_delta=float(cfg_yaml.get("co_sensitivity_min_rel_delta", 1e-2)),
                            variant="visible",
                        )
                        inv_vis: AffineInvarianceGateResult = run_affine_invariance_gate(
                            compiled,
                            max_abs_delta=float(cfg_yaml.get("co_invariance_max_abs_delta", 1e-3)),
                            max_rel_delta=float(cfg_yaml.get("co_invariance_max_rel_delta", 1e-2)),
                            variant="visible",
                        )
                        sens_hid: ObjectiveSensitivityGateResult | None = None
                        inv_hid: AffineInvarianceGateResult | None = None
                        if hidden_dynamic_gates_enabled and sens_vis.ok and inv_vis.ok:
                            sens_hid = run_objective_sensitivity_gate(
                                compiled,
                                min_abs_delta=float(cfg_yaml.get("co_sensitivity_min_abs_delta", 1e-3)),
                                min_rel_delta=float(cfg_yaml.get("co_sensitivity_min_rel_delta", 1e-2)),
                                variant="hidden",
                            )
                            inv_hid = run_affine_invariance_gate(
                                compiled,
                                max_abs_delta=float(cfg_yaml.get("co_invariance_max_abs_delta", 1e-3)),
                                max_rel_delta=float(cfg_yaml.get("co_invariance_max_rel_delta", 1e-2)),
                                variant="hidden",
                            )
                        gate_entry.update(
                            {
                                "co_enabled": True,
                                "co_sensitivity_ok": bool(sens_vis.ok)
                                and (True if sens_hid is None else bool(sens_hid.ok)),
                                "co_sensitivity_visible_ok": sens_vis.ok,
                                "co_sensitivity_visible_reason": sens_vis.reason,
                                "co_sensitivity_visible_abs_delta": sens_vis.abs_delta,
                                "co_sensitivity_visible_rel_delta": sens_vis.rel_delta,
                                "co_sensitivity_visible_trace": sens_vis.trace,
                                "co_sensitivity_hidden_ok": None if sens_hid is None else sens_hid.ok,
                                "co_sensitivity_hidden_reason": None if sens_hid is None else sens_hid.reason,
                                "co_sensitivity_hidden_abs_delta": None if sens_hid is None else sens_hid.abs_delta,
                                "co_sensitivity_hidden_rel_delta": None if sens_hid is None else sens_hid.rel_delta,
                                "co_sensitivity_hidden_trace": None if sens_hid is None else sens_hid.trace,
                                "co_invariance_ok": bool(inv_vis.ok) and (True if inv_hid is None else bool(inv_hid.ok)),
                                "co_invariance_visible_ok": inv_vis.ok,
                                "co_invariance_visible_reason": inv_vis.reason,
                                "co_invariance_visible_abs_delta": inv_vis.abs_delta,
                                "co_invariance_visible_rel_delta": inv_vis.rel_delta,
                                "co_invariance_visible_trace": inv_vis.trace,
                                "co_invariance_hidden_ok": None if inv_hid is None else inv_hid.ok,
                                "co_invariance_hidden_reason": None if inv_hid is None else inv_hid.reason,
                                "co_invariance_hidden_abs_delta": None if inv_hid is None else inv_hid.abs_delta,
                                "co_invariance_hidden_rel_delta": None if inv_hid is None else inv_hid.rel_delta,
                                "co_invariance_hidden_trace": None if inv_hid is None else inv_hid.trace,
                            }
                        )
                        co_ok = bool(gate_entry.get("co_sensitivity_ok")) and bool(gate_entry.get("co_invariance_ok"))
                        if not co_ok:
                            visible_fail = (not sens_vis.ok) or (not inv_vis.ok)
                            if not sens_vis.ok:
                                reason = sens_vis.reason
                            elif not inv_vis.ok:
                                reason = inv_vis.reason
                            elif sens_hid is not None and not sens_hid.ok:
                                reason = sens_hid.reason
                            else:
                                reason = (inv_hid.reason if inv_hid is not None else "co_gate_failed")
                            gate_entry["dynamic_ok"] = False
                            gate_entry["dynamic_reason"] = reason
                            gate_entry["dynamic_error_code"] = _classify_failure("dynamic", reason)
                            _record_gate_entry(gate_entry)

                            # Directed repair only uses VISIBLE counterexamples.
                            if (
                                attempt < max_repair_rounds
                                and directed_repair_enabled
                                and directed_repair_prompt
                                and visible_fail
                                and (directed_repair_max_parents <= 0 or directed_repair_parents_used < directed_repair_max_parents)
                            ):
                                parent_sig = _candidate_signature(ir)
                                if parent_sig not in directed_repair_parent_signatures:
                                    directed_repair_parent_signatures.add(parent_sig)
                                    directed_repair_parents_used += 1

                                    gate_spec = {
                                        "gate": "COAlignment",
                                        "objective_sensitivity": {
                                            "min_abs_delta": float(cfg_yaml.get("co_sensitivity_min_abs_delta", 1e-3)),
                                            "min_rel_delta": float(cfg_yaml.get("co_sensitivity_min_rel_delta", 1e-2)),
                                        },
                                        "affine_invariance": {
                                            "max_abs_delta": float(cfg_yaml.get("co_invariance_max_abs_delta", 1e-3)),
                                            "max_rel_delta": float(cfg_yaml.get("co_invariance_max_rel_delta", 1e-2)),
                                        },
                                        "note": "Child must pass both visible and hidden variants to be accepted.",
                                    }
                                    fail_report = {
                                        "failed_gate": "COAlignment",
                                        "reason": reason,
                                        "visible": {
                                            "sensitivity": sens_vis.trace or {},
                                            "invariance": inv_vis.trace or {},
                                        },
                                    }
                                    counterexamples: List[Dict[str, Any]] = []
                                    counterexamples.extend(_extract_counterexamples_from_trace(sens_vis.trace))
                                    counterexamples.extend(_extract_counterexamples_from_trace(inv_vis.trace))

                                    LOGGER.warning(
                                        "Directed repair enqueue (CO gates) for gen=%d, idx=%d, name=%s (strategies=%s)",
                                        gen,
                                        idx,
                                        ir.name,
                                        ",".join(directed_repair_strategies),
                                    )
                                    for strat in directed_repair_strategies:
                                        try:
                                            children = _directed_repair_children(
                                                ir,
                                                strategy=strat,
                                                gate_spec=gate_spec,
                                                fail_report=fail_report,
                                                counterexamples=counterexamples,
                                                global_feedback=global_feedback,
                                            )
                                            for child in children:
                                                child.name = f"{child.name}_p{idx}"
                                                population.append(child)
                                                sample_ops.append(f"DR_{strat.upper()}")
                                        except Exception as exc:  # noqa: BLE001
                                            LOGGER.warning(
                                                "Directed repair failed for gen=%d, idx=%d, strategy=%s: %s",
                                                gen,
                                                idx,
                                                strat,
                                                exc,
                                            )
                                    dynamic_fail += 1
                                    break

                            if attempt < max_repair_rounds and (repair_prompt or m3_prompt):
                                LOGGER.warning(
                                    "CO gates failed for gen=%d, idx=%d, name=%s: reason=%s; "
                                    "attempting repair (repair_round=%d/%d)",
                                    gen,
                                    idx,
                                    ir.name,
                                    reason,
                                    attempt + 1,
                                    max_repair_rounds,
                                )
                                try:
                                    failure_payload = _build_failure_payload(
                                        generation=gen,
                                        index=idx,
                                        attempt=attempt,
                                        stage="dynamic_gate",
                                        code=gate_entry.get("dynamic_error_code", "E_DYNAMIC_OTHER"),
                                        message=reason,
                                        extra={
                                            "sensitivity": {
                                                "ok": sens_vis.ok,
                                                "abs_delta": sens_vis.abs_delta,
                                                "rel_delta": sens_vis.rel_delta,
                                                "trace": sens_vis.trace,
                                            },
                                            "invariance": {
                                                "ok": inv_vis.ok,
                                                "abs_delta": inv_vis.abs_delta,
                                                "rel_delta": inv_vis.rel_delta,
                                                "trace": inv_vis.trace,
                                            },
                                        },
                                    )

                                    if m3_prompt:
                                        try:
                                            ir = m3_simplify_loss(
                                                m3_prompt,
                                                ir,
                                                failure_payload,
                                                global_feedback=global_feedback,
                                            )
                                            llm_op = "M3_REPAIR"
                                            continue
                                        except Exception as exc:  # noqa: BLE001
                                            LOGGER.warning(
                                                "Failed to simplify (M3) for gen=%d, idx=%d: %s",
                                                gen,
                                                idx,
                                                exc,
                                            )

                                    if repair_prompt:
                                        ir = repair_free_loss(repair_prompt, ir, failure_payload)
                                        llm_op = "REPAIR"
                                        continue
                                except Exception as exc:  # noqa: BLE001
                                    LOGGER.warning(
                                        "Failed to repair CO gate error for gen=%d, idx=%d: %s",
                                        gen,
                                        idx,
                                        exc,
                                    )
                            dynamic_fail += 1
                            break
                    else:
                        gate_entry["co_enabled"] = False

                    pref_res: PreferenceSemanticGateResult | None = None
                    if pref_semantic_gate_enabled:
                        pref_vis = run_preference_semantic_gates(
                            compiled,
                            trials=pref_semantic_trials,
                            batch_size=pref_semantic_batch_size,
                            min_pass_rate=pref_semantic_min_pass_rate,
                            swap_tolerance=pref_semantic_swap_tolerance,
                            gap_min_ratio=pref_semantic_gap_min_ratio,
                            variant="visible",
                        )
                        pref_hid: PreferenceSemanticGateResult | None = None
                        if hidden_dynamic_gates_enabled and pref_vis.ok:
                            pref_hid = run_preference_semantic_gates(
                                compiled,
                                trials=pref_semantic_trials,
                                batch_size=pref_semantic_batch_size,
                                min_pass_rate=pref_semantic_min_pass_rate,
                                swap_tolerance=pref_semantic_swap_tolerance,
                                gap_min_ratio=pref_semantic_gap_min_ratio,
                                variant="hidden",
                            )
                        pref_ok = bool(pref_vis.ok) and (True if pref_hid is None else bool(pref_hid.ok))
                        pref_res = pref_vis
                        gate_entry.update(
                            {
                                "pref_ok": pref_ok,
                                "pref_reason": pref_vis.reason
                                if not pref_vis.ok
                                else (pref_hid.reason if pref_hid is not None and not pref_hid.ok else "ok"),
                                "pref_visible_ok": pref_vis.ok,
                                "pref_visible_reason": pref_vis.reason,
                                "pref_visible_mono_pass_rate": pref_vis.mono_pass_rate,
                                "pref_visible_swap_pass_rate": pref_vis.swap_pass_rate,
                                "pref_visible_gap_pass_rate": pref_vis.gap_pass_rate,
                                "pref_visible_trace": pref_vis.trace,
                                "pref_hidden_ok": None if pref_hid is None else pref_hid.ok,
                                "pref_hidden_reason": None if pref_hid is None else pref_hid.reason,
                                "pref_hidden_mono_pass_rate": None if pref_hid is None else pref_hid.mono_pass_rate,
                                "pref_hidden_swap_pass_rate": None if pref_hid is None else pref_hid.swap_pass_rate,
                                "pref_hidden_gap_pass_rate": None if pref_hid is None else pref_hid.gap_pass_rate,
                                "pref_hidden_trace": None if pref_hid is None else pref_hid.trace,
                            }
                        )
                        if not pref_ok:
                            visible_fail = not pref_vis.ok
                            gate_entry["dynamic_error_code"] = _classify_failure(
                                "dynamic",
                                gate_entry.get("pref_reason", pref_vis.reason),
                            )
                            _record_gate_entry(gate_entry)

                            if (
                                attempt < max_repair_rounds
                                and directed_repair_enabled
                                and directed_repair_prompt
                                and visible_fail
                                and (directed_repair_max_parents <= 0 or directed_repair_parents_used < directed_repair_max_parents)
                            ):
                                parent_sig = _candidate_signature(ir)
                                if parent_sig not in directed_repair_parent_signatures:
                                    directed_repair_parent_signatures.add(parent_sig)
                                    directed_repair_parents_used += 1

                                    gate_spec = {
                                        "gate": "PreferenceSemantics",
                                        "checks": {
                                            "min_pass_rate": float(pref_semantic_min_pass_rate),
                                            "swap_tolerance": float(pref_semantic_swap_tolerance),
                                            "gap_min_ratio": float(pref_semantic_gap_min_ratio),
                                        },
                                        "note": "Child must pass both visible and hidden variants to be accepted.",
                                    }
                                    fail_report = {
                                        "failed_gate": "PreferenceSemantics",
                                        "reason": pref_vis.reason,
                                        "trace": pref_vis.trace or {},
                                    }
                                    counterexamples = _extract_counterexamples_from_trace(pref_vis.trace)

                                    LOGGER.warning(
                                        "Directed repair enqueue (pref gates) for gen=%d, idx=%d, name=%s (strategies=%s)",
                                        gen,
                                        idx,
                                        ir.name,
                                        ",".join(directed_repair_strategies),
                                    )
                                    for strat in directed_repair_strategies:
                                        try:
                                            children = _directed_repair_children(
                                                ir,
                                                strategy=strat,
                                                gate_spec=gate_spec,
                                                fail_report=fail_report,
                                                counterexamples=counterexamples,
                                                global_feedback=global_feedback,
                                            )
                                            for child in children:
                                                child.name = f"{child.name}_p{idx}"
                                                population.append(child)
                                                sample_ops.append(f"DR_{strat.upper()}")
                                        except Exception as exc:  # noqa: BLE001
                                            LOGGER.warning(
                                                "Directed repair failed for gen=%d, idx=%d, strategy=%s: %s",
                                                gen,
                                                idx,
                                                strat,
                                                exc,
                                            )
                                    dynamic_fail += 1
                                    break

                            if attempt < max_repair_rounds and (repair_prompt or m3_prompt):
                                LOGGER.warning(
                                    "Preference gates failed for gen=%d, idx=%d, name=%s: reason=%s; "
                                    "attempting repair (repair_round=%d/%d)",
                                    gen,
                                    idx,
                                    ir.name,
                                    gate_entry.get("pref_reason", pref_vis.reason),
                                    attempt + 1,
                                    max_repair_rounds,
                                )
                                try:
                                    failure_payload = _build_failure_payload(
                                        generation=gen,
                                        index=idx,
                                        attempt=attempt,
                                        stage="preference_gate",
                                        code=gate_entry.get("dynamic_error_code", "E_PREF_SEMANTIC"),
                                        message=gate_entry.get("pref_reason", pref_vis.reason),
                                        extra={
                                            "mono_pass_rate": pref_vis.mono_pass_rate,
                                            "swap_pass_rate": pref_vis.swap_pass_rate,
                                            "gap_pass_rate": pref_vis.gap_pass_rate,
                                            "gate_trace": pref_vis.trace,
                                        },
                                    )

                                    if m3_prompt:
                                        try:
                                            ir = m3_simplify_loss(
                                                m3_prompt,
                                                ir,
                                                failure_payload,
                                                global_feedback=global_feedback,
                                            )
                                            llm_op = "M3_REPAIR"
                                            continue
                                        except Exception as exc:  # noqa: BLE001
                                            LOGGER.warning(
                                                "Failed to simplify (M3) for gen=%d, idx=%d: %s",
                                                gen,
                                                idx,
                                                exc,
                                            )

                                    if repair_prompt:
                                        ir = repair_free_loss(repair_prompt, ir, failure_payload)
                                        llm_op = "REPAIR"
                                        continue
                                except Exception as exc:  # noqa: BLE001
                                    LOGGER.warning(
                                        "Failed to repair preference gate error for gen=%d, idx=%d: %s",
                                        gen,
                                        idx,
                                        exc,
                                    )
                            dynamic_fail += 1
                            LOGGER.warning(
                                "Preference gates failed for gen=%d, idx=%d, name=%s: reason=%s",
                                gen,
                                idx,
                                ir.name,
                                pref_res.reason,
                            )
                            break

                    if pref_res is None or pref_res.ok:
                        _record_gate_entry(gate_entry)

                    # Candidate passes all gates; queue it for evaluation.
                    eval_candidates[idx] = ir
                    ir_payload = asdict(ir)
                    eval_jobs.append(
                        (
                            ir_payload,
                            hf_cfg_dict,
                            free_cfg_dict,
                            "",  # device to be filled after we know available devices
                            operator_whitelist,
                            run_dir,
                            gen,
                            idx,
                            baseline_early_valid,
                            baseline_epoch_objectives,
                            early_eval_steps,
                        )
                    )
                    seen_signatures.add(signature)
                    break
                if resampled:
                    continue
                break

        # Evaluate all surviving candidates in parallel across GPUs / devices.
        # We ensure that at any moment, at most one long-lived worker process
        # is active per device, so each GPU holds at most one candidate's
        # training state/cache.
        results: List[Tuple[int, Dict[str, Any]]] = []
        if eval_jobs:
            devices = _get_available_devices(hf_cfg.device)
            if not devices:
                devices = [hf_cfg.device]

            max_parallel = cfg_yaml.get("max_parallel_devices")
            if max_parallel is not None:
                try:
                    max_parallel_int = max(int(max_parallel), 1)
                except (TypeError, ValueError):
                    max_parallel_int = len(devices)
                if len(devices) > max_parallel_int:
                    LOGGER.info(
                        "Limiting parallel evaluation devices: available=%s max_parallel_devices=%d",
                        str(devices),
                        max_parallel_int,
                    )
                    devices = list(devices)[:max_parallel_int]

            ctx = mp.get_context("spawn")

            # Partition jobs by device in a round-robin fashion.
            jobs_by_device: Dict[str, List[
                Tuple[
                    Dict[str, Any],
                    Dict[str, Any],
                    Dict[str, Any],
                    str,
                    List[str],
                    str,
                    int,
                    int,
                    float | None,
                    List[float] | None,
                    int,
                ]
            ]] = {dev: [] for dev in devices}

            for j_idx, job in enumerate(eval_jobs):
                dev = devices[j_idx % len(devices)]
                job_with_dev = list(job)
                job_with_dev[3] = dev
                jobs_by_device[dev].append(tuple(job_with_dev))  # type: ignore[arg-type]

            result_queue: "mp.Queue[Tuple[int, Dict[str, Any]]]" = ctx.Queue()
            processes: List[mp.Process] = []

            total_jobs = 0
            for dev, dev_jobs in jobs_by_device.items():
                if not dev_jobs:
                    continue
                total_jobs += len(dev_jobs)
                p = ctx.Process(target=_device_worker, args=(dev_jobs, result_queue))
                p.start()
                processes.append(p)

            # Collect all results.
            collected = 0
            heartbeat_s = float(cfg_yaml.get("eval_heartbeat_seconds", 300) or 300)
            heartbeat_s = max(5.0, heartbeat_s)
            while collected < total_jobs:
                try:
                    idx, fitness = result_queue.get(timeout=heartbeat_s)
                except queue.Empty:
                    states = [
                        f"pid={p.pid} {p.name} {('alive' if p.is_alive() else 'dead')} {_format_exitcode(p.exitcode)}"
                        for p in processes
                    ]
                    LOGGER.info(
                        "Waiting for eval results: collected=%d/%d workers=[%s]",
                        collected,
                        total_jobs,
                        "; ".join(states),
                    )
                    # If any worker has exited abnormally, fail fast with a clear error.
                    crashed = [p for p in processes if p.exitcode not in (None, 0)]
                    if crashed:
                        LOGGER.error(
                            "Evaluation worker crashed before producing all results: %s",
                            "; ".join(
                                f"pid={p.pid} exit={_format_exitcode(p.exitcode)}" for p in crashed
                            ),
                        )
                        raise RuntimeError(
                            "Evaluation worker crashed (see worker fatal logs under the run directory)."
                        )
                    # If all workers have exited but we still don't have all results,
                    # the queue likely lost messages due to an abrupt termination.
                    if all(p.exitcode is not None for p in processes) and collected < total_jobs:
                        raise RuntimeError(
                            "All evaluation workers exited but results are incomplete; "
                            "this often indicates an external kill (e.g., OOM/SIGKILL)."
                        )
                    continue

                results.append((idx, fitness))
                collected += 1

            for p in processes:
                p.join()
                if p.exitcode not in (None, 0):
                    LOGGER.warning(
                        "Evaluation worker exited non-zero after result collection: pid=%s exit=%s",
                        str(p.pid),
                        _format_exitcode(p.exitcode),
                    )

        # Integrate evaluation results back into the evolutionary loop.
        for idx, fitness in sorted(results, key=lambda x: x[0]):
            evaluated += 1
            ir = eval_candidates[idx]

            descriptor: Dict[str, Any] | None = None
            novelty = 0.0
            try:
                compiled = compile_free_loss_candidate(ir, operator_whitelist=operator_whitelist)
                behavior = _behavior_descriptor(
                    compiled,
                    deltas=behavior_deltas,
                    batch_size=pref_semantic_batch_size,
                )
                if behavior is not None:
                    descriptor = {
                        "behavior": behavior,
                        "ops": list(ir.operators_used or []),
                        "hyperparams": list((ir.hyperparams or {}).keys()),
                        "thought": _thought_tokens(ir),
                        "signature": _candidate_signature(ir),
                    }
                    novelty = _novelty_score(
                        descriptor,
                        diversity_archive,
                        k=novelty_k,
                        ops_weight=novelty_ops_weight,
                        hparam_weight=novelty_hparam_weight,
                        behavior_weight=novelty_behavior_weight,
                        thought_weight=novelty_thought_weight,
                    )
            except Exception:  # noqa: BLE001
                descriptor = None
                novelty = 0.0

            fitness["novelty"] = novelty

            hf_like_score = float(fitness["hf_like_score"])
            epoch_mean = fitness.get("epoch_objective_mean")
            epoch_mean_val = float(epoch_mean) if epoch_mean is not None else float("nan")
            epoch_violations = fitness.get("epoch_baseline_violations")
            early_eval = fitness.get("early_eval") or {}
            early_eval_steps = early_eval.get("steps")
            early_stopped = early_eval.get("early_stopped")
            better_than_baseline = None
            baseline_compare_value = float("nan")
            if baseline_epoch_objectives:
                # When epoch-wise baselines exist, decide "better than baseline" by
                # requiring that the latter half of epochs are all <= their baseline
                # counterparts. This tolerates noisy early training as long as the
                # model is consistently better in the later stage.
                epoch_eval = fitness.get("epoch_eval") or {}
                cand_epoch_objectives = epoch_eval.get("objectives") or []
                compare_len = min(len(cand_epoch_objectives), len(baseline_epoch_objectives))
                if compare_len > 0:
                    base_last = float(baseline_epoch_objectives[compare_len - 1])
                    baseline_compare_value = base_last
                    start_idx = compare_len // 2
                    better_than_baseline = all(
                        float(cand_epoch_objectives[i]) <= float(baseline_epoch_objectives[i])
                        for i in range(start_idx, compare_len)
                    )
                elif baseline_hf_score is not None:
                    baseline_compare_value = float(baseline_hf_score)
                    # Lower score is better.
                    better_than_baseline = hf_like_score <= baseline_hf_score
            elif baseline_hf_score is not None:
                baseline_compare_value = float(baseline_hf_score)
                # Lower score is better.
                better_than_baseline = hf_like_score <= baseline_hf_score

            LOGGER.info(
                "Gen %d cand %d: hf_like_score=%.6f, validation_objective=%.6f, "
                "epoch_mean=%.6f, epoch_violations=%s, early_eval_steps=%s, early_stopped=%s, "
                "baseline=%.6f, better_than_baseline=%s",
                gen,
                idx,
                hf_like_score,
                float(fitness["validation_objective"]),
                epoch_mean_val,
                str(epoch_violations),
                str(early_eval_steps),
                str(early_stopped),
                baseline_compare_value
                if not math.isnan(baseline_compare_value)
                else (float(baseline_hf_score) if baseline_hf_score is not None else float("nan")),
                str(better_than_baseline),
            )

            cand_entry_log = {
                "generation": gen,
                "index": idx,
                "ir": asdict(ir),
                "fitness": fitness,
                "better_than_baseline": better_than_baseline,
                "novelty": novelty,
                "diversity_descriptor": descriptor,
            }
            pending_candidates.append(cand_entry_log)
            pending_fitness.append(
                {
                    "generation": gen,
                    "index": idx,
                    "hf_like_score": fitness["hf_like_score"],
                    "validation_objective": fitness["validation_objective"],
                    "epoch_objective_mean": epoch_mean,
                    "epoch_baseline_violations": epoch_violations,
                    "epoch_better_than_baseline": fitness.get("epoch_better_than_baseline"),
                    "early_eval_steps": early_eval_steps,
                    "early_stopped": early_stopped,
                    "baseline_hf_score": baseline_hf_score,
                    "better_than_baseline": better_than_baseline,
                    "novelty": novelty,
                }
            )
            elite_entry = {
                "generation": gen,
                "index": idx,
                "ir": ir,
                "fitness": fitness,
                "novelty": novelty,
            }
            gen_elites.append(elite_entry)

            if descriptor is not None:
                diversity_archive.append(descriptor)
                if len(diversity_archive) > diversity_archive_size:
                    diversity_archive.pop(0)

        def _elite_key(entry: Dict[str, Any]) -> Tuple[float, float, float]:
            score = float(entry["fitness"]["hf_like_score"])
            pair_count = float(entry["fitness"].get("pair_count", 0) or 0)
            violations = entry["fitness"].get("epoch_baseline_violations")
            if violations is not None:
                return (float(violations), score, pair_count)
            if baseline_hf_score is None:
                # Fallback: purely score-based, with pair_count as a tie-breaker.
                return (0.0, score, pair_count)
            # Prefer candidates that beat the baseline (lower score).
            better = score <= baseline_hf_score
            flag = 0.0 if better else 1.0
            # When better than baseline, fewer pairs is preferred; otherwise ignore pair_count.
            effective_pairs = pair_count if better else 0.0
            return (flag, score, effective_pairs)

        gen_elites.sort(key=_elite_key)
        LOGGER.info(
            "Generation %d summary: static_fail=%d, dynamic_fail=%d, evaluated=%d, new_elites=%d",
            gen,
            static_fail,
            dynamic_fail,
            evaluated,
            len(gen_elites),
        )
        elites.extend(gen_elites)
        elites.sort(key=_elite_key)
        elites = elites[:elite_size]

        if gen_elites:
            diverse_pool = diverse_elites + gen_elites
            diverse_elites = _select_parents(
                diverse_pool,
                min(diversity_archive_size, len(diverse_pool)),
            )

        attempted = static_fail + dynamic_fail + evaluated
        prev_dynamic_fail_rate = float(dynamic_fail) / float(max(1, attempted))
        stall_eps = float(cfg_yaml.get("scheduler_stall_eps", 1e-4))
        current_best = float(elites[0]["fitness"]["hf_like_score"]) if elites else float("inf")
        if current_best < best_hf_so_far - stall_eps:
            best_hf_so_far = current_best
            stalled_gens = 0
        else:
            stalled_gens += 1

        _flush_jsonl_logs()
        _save_checkpoint(run_dir, _checkpoint_state(gen + 1))
        _write_best_candidate_snapshot()

    _flush_jsonl_logs()
    _write_run_analysis(
        run_dir,
        baseline_hf_score=baseline_hf_score,
        generations=generations,
        population_size=population_size,
        gate_failure_stats=gate_failure_stats,
        elites=elites,
    )

    _write_best_candidate_snapshot()
    if elites:
        best = elites[0]
        LOGGER.info(
            "Search complete. Best hf_like_score=%.6f (generation=%d, index=%d)",
            best["fitness"]["hf_like_score"],
            best["generation"],
            best["index"],
        )
    else:
        LOGGER.info("Search complete. No candidate passed dynamic gates; no elites selected.")
